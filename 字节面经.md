

## 字节面经

#### 1.堆排序

基本思想：

堆就是完全二叉树

大根堆

小根堆

主要核心就是堆化，一般是用父节点和他的孩子结点进行比较，取最大的孩子结点和其进行交换。

时间复杂度为O(nlogn)，最好最坏都是O(nlogn)

不稳定排序



#### 2.从输入url到页面加载完成发生了什么

**1.浏览器查找当前URL是否存在缓存，并比较缓存是否过期。**

万般无奈之下找向了**浏览器缓存**，让其查找是否有这家伙的记录，结果并没有发现，此时找向**系统缓存**，主要去查找了系统中的hosts文件，同样没有，此时找向**路由器缓存**，查看路由器映射表，然而，并没有！

**2.DNS解析URL对应的IP**

计算机将域名发给了**本地DNS服务器**（提供本地连接的服务商），本地DNS服务器找不到会将域名发送给其他服务器，进行递归过程，首先会发送到**根域名服务器**去找，返回**顶级域名服务**器的IP地址，再请求顶级域名服务器IP返回**二级域名服务器**IP，再请求二级域名服务器IP返回三级域名服务器IP......直到找到对应的IP地址，返回给浏览器。

**3.根据IP建立TCP连接(三次握手)**

**4.浏览器向服务器发送HTTP请求**

**5.服务器处理请求，浏览器接收响应并渲染页面**

**6.关闭TCP连接**



**从网卡开始的流程**

1.网卡收到的数据是光信号或电信号，然后将其还原成数字信息。

然后 **检查** 数据包中MAC头部中的 **接收方的MAC地址**，若不是发给自己，则丢弃数据包；若数据包是发给自己，则将数字信息保存到网卡内部缓冲区。

2.网卡处理完数字信号后，网卡通过中断将数据包达到的事件通知给CPU,CPU用网卡驱动从网卡缓冲区读取接收到的数据，并调用协议栈

3.ip和tcp层会逐层处理，剔除协议头部，将数据转交到上层。而发送数据时，TCP、IP等也会一层层的为数据包加上头部	

ip层：

- IP模块会检查IP头部以判断数据是不是发给自己
- 判断数据包是否分片，如果分片则缓存起来等待分片全部到达再还原成数据包
- 根据IP头部的协议号字段，将包转给TCP模块或UDP模块处理

tcp层：

TCP模块会根据 **标志位** 来进行不同处理，假设服务端收到该报文，会进行如下处理：

**如果 SYN=1，表示这是请求连接的包**。

- 首先检查接收方端口号，然后检查有没有与该端口号相同且处于等待连接状态的套接字。如果没有，则返回错误通知的包；
- 如果有，则为这个套接字复制一个新副本，将发送方IP、端口等必要信息写入套接字，同时分配用于发送缓冲区和接收缓冲区的内存空间。
- 最后返回给数据客户端，客户端会再次确认，这属于TCP连接三次握手的一部分。

**如果是正常数据包**，TCP模块需要检查该包对应的套接字。然后提取出数据，存放到缓冲区。此时，如果应用程序调用socket的read()，数据就可以转交给应用程序了。如果应用程序不来获取数据，数据则一直保存在缓冲区中。


4.数据就到应用层，应用层通过socket来操作数据。

**socket含义**

**对应用层来说**，可通过socket与内核中的网络协议栈通信，所以socket提供了网络编程的系统调用接口

**从linux文件系统来说**，socket是一个打开的文件

**从linux内核来说**，socket是一个通信的端点



Socket基于内核的回调机制

- 传统IO模型一个连接一个线程处理，然后遍历连接，CPU光遍历连接就已经满负荷。耗费大量线程，频繁切换线程环境，只适合低并发应用。
- 进一步，可以一个线程管理多个socket(也就是多个fd)，这也是NIO中的select机制。虽然降低了线程数，提高了并发能力，但遍历的瓶颈一直都在。
- 问题最终由异步机制搞定。linux内核2.6版本提出了新的多路复用机制 epoll，套接字提供了回调函数，内核从网卡读取数据后就会回调该函数。

回调函数：

目的：

​	避免无效工作，提高处理效率。

两个基本条件：

**1.Class A调用Class B中的X方法**

**2.ClassB中X方法执行的过程中调用Class A中的Y方法完成回调**



**文件描述符（File Description）**简称fd，是一个正整数，起到一个文件索引的作用，保存了一个指向文件的指针。



#### 3.HTTPs和HTTP请求

HTTP1.0默认使用短连接，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码

```java
Connection:keep-alive
```

HTTP2.0

**多路复用**（MultiPlexing），即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。



1. **端口** ：HTTP端口：80   HTTPS端口：443
2. **安全性和资源消耗：** HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL（Secure Socket Layer，安全套接层）/TLS（Transport Layer Security,安全层传输协议）之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

HTTPS和HTTP的主要区别如下：

1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。

3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。


#### 4.UDP如何实现可靠传输？

最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。

- 1、添加seq/ack机制，确保数据发送到对端
- 2、添加发送和接收缓冲区，主要是用户超时重传。
- 3、添加超时重传机制。



#### 5.https如何加密，加密算法

混合加密

- 使用非对称密钥加密方式，传输对称密钥加密方式所需要的密钥，从而保证安全性;
- 获取到密钥后，再使用对称密钥加密方式进行通信，从而保证效率。



![img](https://img-blog.csdn.net/20180622174607442?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE3Nzk3MjQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



![img](https://upload-images.jianshu.io/upload_images/6728519-e5d70d73b269272a.jpg?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

常见加密的种类

1）哈希算法

md5加密，sha加密

2）对称加密算法

DES,AES

3）非对称加密算法



#### 6.数据库索引的优缺点及索引什么时候失效？

索引的分类？

**普通索引** ------ 最基本的索引 没有任何限制

**唯一索引** ------ 索引列的值必须唯一 但允许有空值

**主键索引** ------ 不仅唯一而且不允许与空值 一般在建表的同时创建主键索引

**单列索引** 和 **组合索引**：

单列索引指只包含一个列的索引，一个表中可以有多个列的索引

组合索引指多个字段组合上创建的索引，遵循最左前缀集合

**哈希索引**：

InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。



优点：**提高检索效率**

缺点：

**有维护成本**



```properties
CREATE INDEX index_name ON table_name (column_name)
```



哪些情况或字段适合加索引？
在经常需要搜索的列上（where子句）
主键列上可以确保列的唯一性
在经常需要排序(order by),分组(group by)和 distinct 列上加索引可以加快排序查询



哪些情况不适合创建索引？
查询中很少使用到的列
很少数据的列（性别）
定义为 text 和 image 和 bit 数据类型的列
表的修改大大多于查询



哪些情况会造成索引失效？

**where条件中有or,除非or的所有字段都有索引，只要有一个没有索引，就不走索引**

如果条件中有 or，即使其中有条件带索引也不会使用

对于多列索引，不是使用的第一部分，则不会使用索引

like 查询以%开头
在索引的列上使用表达式或者函数会使索引失效



实现原理？

通过B Tree缩小扫描范围，底层索引进行了排序、分区，索引会携带数据在表中的“物理地址”，最终通过索引检索到数据之后，获取到关联的物理地址，通过物理地址定位表中的数据，效率是最高的。



InnoDB和MyISAM区别

- 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
- 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- 外键：InnoDB 支持外键。
- 备份：InnoDB 支持在线热备份。
- 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- 其它特性：MyISAM 支持压缩表和空间数据索引。



算法题：

接雨水：

```java
class Solution{
  public int trap(int[] height){
    if(height==null||height.length<3){
      return 0;
    }
    //接雨水的数量
    int sum = 0;
    //left[i]表示第i列左边的最高的列值
    int[] left=new int[height.length];
    left[0]=height[0];
    for(int i=1;i<height.length;i++){
      left[i]=left[i-1]>height[i]?left[i-1]:height[i];
    }
    //right[i]表示第i列右边的最高的列值
    int[] right=new int[height.length];
    right[height.length-1]=height[right.length-1];
    for(int i=height.length-2;i>=0;i--){
      right[i]=right[i+1]>height[i]?right[i+1]:height[i];
    }
    for(int i=1;i<height.length-1;i++){
      sum+=Math.min(left[i],right[i])-height[i];
    }
    return sum;
  }
}
```



N皇后：

```java
class Solution{
  List<List<String>> res=new ArrayList<>();
  
  public List<List<String>> solveNQueens(int n){
    if(n<1){
      return res;
    }
    List<Integer> list=new ArrayList<>();
    help(0,n,list);
    return res;
  }
  public void help(int row,int n,List<Integer> list){
    if(row==n){
      List<String> strList=new ArrayList<>();
      for(Integer num:list){
        char[] t=new char[n];
        Arrays.fill(t,'.');
        t[num]='Q';
        strList.add(new String(t));
      }
      res.add(strList);
      return;
    }
    for(int col=0;col<n;col++){
      if(!list.contains(col)){
        if(!isDiagonalAttack(list,col)){
          list.add(col);
          help(row+1,n,list);
          list.remove(list.size()-1);
        }
      }
    }
  }
  public boolean isDiagonalAttack(List<Integer> currentQueen,int i){
    int currentRow = currentQueen.size();
    int currentCol=i;
    for(int row=0;row<currentQueen.size();row++){
      if(Math.abs(currentRow-row)==Math.abs(currentCol-currentQueen.get(row))){
        return true;
      }
    }
    return false;
  }
}
```



二叉树中的最大路径和

给定一个**非空**二叉树，返回其最大路径和。

本题中，路径被定义为一条从树中任意节点出发，达到任意节点的序列。该路径**至少包含一个**节点，且不一定经过根节点。

```java
class Solution{
  int res=Integer.MIN_VALUE;
  public int maxPathSum(TreeNode root){
    if(root==null){
      return 0;
    }
    dfs(root);
    return res;
  }
  public int dfs(TreeNode root){
    if(root==null){
      return 0;
    }
    int leftMax=Math.max(0,dfs(root.left));
    int rightMax=Math.max(0,dfs(root.right));
    res=Math.max(res,root.val+leftMax+rightMax);
    return root.val+Math.max(leftMax,rightMax);
  }
} 
```



给定单向链表的头指针和一个要删除的节点的值，定义一个函数删除该节点。

```java
public ListNode deleteNode(ListNode head, int val) {
        if(head==null) return head;
        if(head.val==val) return head.next;
        ListNode cur = head;
        while(cur.next!=null&&cur.next.val!=val){
            cur = cur.next;
        }
        
        if(cur.next!=null) cur.next=cur.next.next;
        //而如果是cur.next==null导致的跳出循环，则说明链表中查询完毕也没有找到对应节点，不对链表进行修改。
        
        return head;
}
```



#### 7.redis的Zset实现

Redis 是一个开源的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 

​                                        

渐进式rehash

**扩展或收缩哈希表需要将 `ht[0]` 里面的所有键值对 rehash 到 `ht[1]` 里面， 但是， 这个 rehash 动作并不是一次性、集中式地完成的， 而是分多次、渐进式地完成的。**

1. 为 `ht[1]` 分配空间， 让字典同时持有 `ht[0]` 和 `ht[1]` 两个哈希表。
2. 在字典中维持一个索引计数器变量 `rehashidx` ， 并将它的值设置为 `0` ， 表示 rehash 工作正式开始。
3. 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 `ht[0]` 哈希表在 `rehashidx` 索引上的所有键值对 rehash 到 `ht[1]` ， 当 rehash 工作完成之后， 程序将 `rehashidx` 属性的值增一。
4. 随着字典操作的不断执行， 最终在某个时间点上， `ht[0]` 的所有键值对都会被 rehash 至 `ht[1]` ， 这时程序将 `rehashidx` 属性的值设为 `-1` ， 表示 rehash 操作已完成。



zset底层的存储结构包括**ziplist或skiplist**，在同时满足以下两个条件的时候使用ziplist，其他时候使用skiplist，两个条件如下：

- 有序集合保存的元素数量小于128个
- 有序集合保存的所有元素的长度小于64字节



当ziplist作为zset的底层存储结构时候，**每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值。**

当skiplist作为zset的底层存储结构的时候，**使用skiplist按序保存元素及分值，使用dict来保存元素和分值的映射关系。**



zset基于跳跃表和字典实现的

字典的key保存元素的值，value保存元素的score

字典能以O(1)的复杂度查找成员的分值，但是以无序的方式来保存元素，每次进行范围操作要进行排序；

跳跃表能执行范围操作，但是查找操作由O(1)变成了O(logN)



跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。

为什么使用skiplist而不用平衡树？

1）有序集合会经常进行范围查找操作，跳表里面的双向链表可以十分方便的进行此类操作

2）平衡树的插入和删除操作可能引发树的调整，skiplist的插入和删除只需要修改相邻节点的指针，操作简单快速

3）内存占用上，skiplist比平衡树灵活一些

3）算法实现上简单



#### 8.redis的sentinel和cluster区别和各自适用场景

slaveof

主从复制：

1.数据冗余：实现了数据的热备份

2.故障恢复：主节点出现问题，由从节点提供服务

3.负载均衡：在主从复制的基础上，配合读写分离,由主节点提供写服务，由从节点提供读服务，分担服务器负载，尤其在写少读多的场景下

4.高可用的基石：是哨兵和集群能够实施的基础



哨兵：

Sentinel充当了Redis主从实例的守卫者，是构成Redis高可用的一个重要组成部分。

作用：

集群监控：负责监控redis master和slave进程是否正常工作

消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员

故障转移：主节点挂掉了，自动转移到从节点上

配置中心：如果故障转移发生了，通知客户端新的master地址



用文字描述一下**故障切换（failover）**的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量（quorum）达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过**发布订阅模式**，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。



**Redis主备切换的数据丢失问题？**

1.**异步复制导致的数据丢失**

因为 master->slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。

2.**脑裂导致的数据丢失**

脑裂，也就是说，某个 master 所在机器突然**脱离了正常的网络**，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会**认为** master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的**脑裂**。

```java
min-slaves-to-write 1
min-slaves-max-lag 10
```

表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。

如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。

- **减少异步复制数据的丢失**

有了 `min-slaves-max-lag` 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。

- **减少脑裂的数据丢失**

如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。



**sentinel没有配置从节点信息如何知道从节点信息的？**

每隔10秒，sentinel进行向主节点发送info命令，用于发现新的slave节点



选举**sentinel**领导者 使用的raft算法，大致思路：

1、每个做主观下线的sentinel节点像其他sentinel节点发送命令，要求将自己设置为领导者

2、接收到的sentinel可以同意或者拒绝

3、如果该sentinel节点发现自己的票数已经超过半数并且超过了quorum

4、如果此过程选举出了多个领导者，那么将等待一段时重新进行选举

 

 

**主节点选举**：选举出可以代替主节点的slave从节点

1、选择健康状态从节点（排除主观下线、断线），排除5秒钟没有心跳的、排除主节点失联超过10*down-after-millisecends

2、选择slave-priority高的从节点优先级列表

3、**选择偏移量大的**

如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。

4、选择runid小的



```properties
配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。

sentinel monitor mymaster 192.168.11.128 6379 2
```



**Redis sentinel本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。**

适用于高可用Cache,存储等场景，内存受限于单机



**brpop会阻塞队列，并且每次也是弹出一个消息，如果没有消息会阻塞。**



**集群：**

即使使用哨兵，redis每个实例也是全量存储，每个redis存储的内容都是完整的数据，浪费内存且有木桶效应。为了最大化利用内存，可以采用集群，就是分布式存储。即每台redis存储不同的内容，共有16384个slot。

每个key通过CRC16校验后对16384取模来决定放置哪个槽

用于大数据量高可用Cache/存储场景



#### 9.redis单线程为什么快？

1.数据存储在内存里，读写数据的时候不会受到磁盘I/O速度的限制

2.数据结构简单，对数据操作也简单

3.采用单线程，避免了不必要的上下文切换和竞争条件，不用考虑锁的问题导致的性能消耗

4.使用多路I/O复用模型，非阻塞I/O

select/poll/epoll 都是 I/O 多路复用的具体实现

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。



**先用epoll_create创建一个epoll对象epfd，再通过epoll_ctl将需要监视的socket添加到epfd中，最后调用epoll_wait等待数据。**



#### 10.mybatis一级缓存和二级缓存

Mybatis是一个半ORM（对象关系映射）框架，它内部封装了JDBC，开发时只需要关注SQL语句本身，不需要花费精力去处理加载驱动、创建连接、创建statement等繁杂的过程。



ORM:将关系数据库中表中的记录映射成对象，以对象的形式展现，程序员可以把对数据库的操作转化为对对象的操作。



一级缓存：

Mybatis的一级缓存是指SqlSession。一级缓存的作用域是一个SqlSession。Mybatis默认开启一级缓存。 在同一个SqlSession中，执行相同的查询SQL，第一次会去查询数据库，并写到缓存中；第二次直接从缓存中取。 当执行SQL时两次查询中间发生了增删改操作，则SqlSession的缓存清空。

二级缓存：

Mybatis的二级缓存是指mapper映射文件。二级缓存的作用域是同一个namespace下的mapper映射文件内容，多个SqlSession共享。Mybatis需要手动设置启动二级缓存。

```properties
mybatis.configuration.cache-enabled=true
```

在同一个namespace下的mapper文件中，执行相同的查询SQL，第一次会去查询数据库，并写到缓存中；第二次直接从缓存中取。

当执行SQL时两次查询中间发生了增删改操作，则二级缓存清空。

**二级缓存比一级缓存速度要快了许多，也说明数据先到二级缓存中读取，如果没有再去一级缓存。**



**通常一个Xml映射文件，都会写一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？**

​	**Mapper接口里的方法，是不能重载的，因为是使用 全限名+方法名 的保存和寻找策略。**

Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MapperStatement。

Mapper 接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，转而执行MapperStatement所代表的sql，然后将sql执行结果返回。



**如何获取自动生成的(主)键值?**

insert 方法总是返回一个int值 ，这个值代表的是插入的行数。

如果采用自增长策略，自动生成的键值在 insert 方法执行完后可以被设置到传入的参数对象中。



一对一、多对一：

通过在resultMap里面配置association

一对多：

在resultMap里面配置collection



**在mapper中如何传递多个参数?**

使用 @param 注解:（用于dao层）

**@Param注解的作用是给参数命名,参数命名后就能根据名字得到参数值,正确的将参数传入sql语句中 。**



@PathVariable（Controller层）

绑定路径中的占位符参数到方法参数变量中





#### 11.spring如何解决循环依赖？

解决的是setter单例模式的循环依赖

使用三级缓存

singletonObjects：第一级缓存，里面放置的是实例化好的单例对象；

earlySingletonObjects：第二级缓存，里面存放的是提前曝光的单例对象；

singletonFactories：第三级缓存，里面存放的是要被实例化的对象的对象工厂。



**1.**先加载A，依次判断(一级缓存)、(二级缓存)、(三级缓存)中是否有A，没有就将A加入(三级缓存)

**2. **A依赖B，先加载B
**2.1** 依次判断(一级缓存)、(二级缓存)、(三级缓存)中是否有B,没有就将B加入(三级缓存)
**2.2** 加载B的依赖，发现依赖A，依次从(一级缓存)、(二级缓存)、(三级缓存)中查找A，发现(三级缓存)有A，将A上升到(二级缓存)中
**2.3 **将A注入B的引用，完成B的加载，将B从(三级缓存)升级至(一级缓存)中

**3.**A依赖的B加载完了，继续加载A完成。将A从(二级缓存)上升到(一级缓存)。



肯定就知道为啥Spring不能解决“A的构造方法中依赖了B的实例对象，同时B的构造方法中依赖了A的实例对象”这类问题了！因为加入singletonFactories三级缓存的前提是执行了构造器，所以构造器的循环依赖没法解决



#### 12.spring两种容器ApplicationContext和BeanFactory装载bean的区别

**BeanFactory：**

BeanFactory在启动的时候不会去实例化Bean，从容器中拿Bean的时候才会去实例化；

**ApplicationContext：**

（1）：如果bean的scope是singleton的，并且lazy-init为false（默认是false，所以可以不用设置），则ApplicationContext启动的时候就实例化该Bean，并且将实例化的Bean放在一个map结构的缓存中，下次再使用该Bean的时候，直接从这个缓存中取
（2）：如果bean的scope是singleton的，并且lazy-init为true，则该Bean的实例化是在第一次使用该Bean的时候进行实例化
（3）：如果bean的scope是prototype的，则该Bean的实例化是在第一次使用该Bean的时候进行实例化



#### 13.spring AOP的原理

面向切面编程。

作用：

​	在程序运行期间，不修改源码对已有方法进行增强。

```
jdk动态代理和cglib
使用JDK动态代理，目标类必须实现的某个接口，如果某个类没有实现接口则不能生成代理对象。
Cglib原理是针对目标类生成一个子类，覆盖其中的所有方法，所以目标类和方法不能声明为final类型。
从执行效率上看，jdk动态代理效率较高。
```

Spring中的AOP有两种实现方式：

1.JDK动态代理

```java
 final UserDao userDao = new UserDaoImpl();
        // newProxyInstance的三个参数解释：
        // 参数1：代理类的类加载器，同目标类的类加载器
        // 参数2：代理类要实现的接口列表，同目标类实现的接口列表
        // 参数3：回调，是一个InvocationHandler接口的实现对象，当调用代理对象的方法时，执行的是回调中的invoke方法
        //proxy为代理对象
        UserDao proxy = (UserDao) Proxy.newProxyInstance(userDao.getClass().getClassLoader(),
                userDao.getClass().getInterfaces(), new InvocationHandler() {

                    @Override
                    // 参数proxy:被代理的对象
                    // 参数method:执行的方法，代理对象执行哪个方法，method就是哪个方法
                    // 参数args:执行方法的参数
                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                        System.out.println("记录日志");
                        Object result = method.invoke(userDao, args);
                        return result;
                    }
                });
        //代理对象执行方法
        proxy.saveUser();
```



2.Cglib动态代理

在实际开发中，可能需要对没有实现接口的类增强，用JDK动态代理的方式就没法实现。采用Cglib动态代理可以对没有实现接口的类产生代理，**实际上是生成了目标类的子类来增强。**

```java
public class CglibProxy {
    public static Object getProxy(final Object cs){
        return Enhancer.create(CustomerServiceImpl.class, new MethodInterceptor() {
            //每次代理类对象执行方法的时候执行该方法
            @Override
            public Object intercept(Object proxy, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
                System.out.println("记录日志");
                return method.invoke(cs,objects);
            }
        });
    }
}
```



切入点：所要代理增强的方法

通知：

整个的invoke方法在执行就是环绕通知

切面（Aspect）

​	切入点和通知（引介）的结合

```java
@Pointcut("execution(* com.zj.service.impl.*.*(..))")
private void ptl(){}

@After("ptl()")
public void writeLog(){
  System.out.println("开始打印日志了。。后置");
}
```



#### 14.spring的生命周期

① 通过构造器或工厂方法创建bean实例

② 为bean的属性设置值和对其他bean的引用

③ 调用bean的初始化方法

④ bean可以使用了

⑤ 当容器关闭时，调用bean的销毁方法



 首先说一下Servlet的生命周期：实例化，初始init，接收请求service，销毁destroy；

 Spring上下文中的Bean生命周期也类似，如下：

（1）**实例化Bean：**

对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。对于ApplicationContext容器，当容器启动结束后，通过获取BeanDefinition对象中的信息，实例化所有的bean。

（2）**设置对象属性（依赖注入）：**

实例化后的对象被封装在BeanWrapper对象中，紧接着，Spring根据BeanDefinition中的信息 以及 通过BeanWrapper提供的设置属性的接口完成依赖注入。

（3）**处理Aware接口：**

接着，Spring会检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给Bean：

①如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String beanId)方法，此处传递的就是Spring配置文件中Bean的id值；

②如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory()方法，传递的是Spring工厂自身。

③如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文；

（4）**BeanPostProcessor：**

如果想对Bean进行一些自定义的处理，那么可以让Bean实现了BeanPostProcessor接口，那将会调用postProcessBeforeInitialization(Object obj, String s)方法。

（5）**InitializingBean 与 init-method：**

如果Bean在Spring配置文件中配置了 init-method 属性，则会自动调用其配置的初始化方法。

（6）如果这个Bean实现了BeanPostProcessor接口，将会调用**postProcessAfterInitialization(Object obj, String s)方法**；由于这个方法是在Bean初始化结束时调用的，所以可以被应用于内存或缓存技术；

> 以上几个步骤完成后，Bean就已经被正确创建了，之后就可以使用这个Bean了。

（7）**DisposableBean：**

当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用其实现的destroy()方法；

（8）**destroy-method：**

最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法



单例对象：

​	出生：容器创建时对象出生

​	活着：只要容器还在，对象一直存活

​	死亡：容器销毁，对象消亡

​	总结：单例对象的生命周期和容器相同

多例对象：

​	出生：当我们使用对象时spring框架为我们创建

​	活着：对象只要是在使用过程中就一直活着

​	死亡：当对象长时间不用，且没有别的对象引用时，由Java的垃圾回收器回收



Spring框架中用到的哪些设计模式？

（1）工厂模式：BeanFactory就是简单工厂模式的体现，用来创建对象的实例；

（2）单例模式：Bean默认为单例模式。

（3）代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术；

（4）模板方法：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。

（5）观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现--ApplicationListener。



spring中的单例bean的线程安全问题

1、在Bean对象中尽量避免定义可变的成员变量（不太现实）。
2、在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。



二叉树的镜像：

```java
class Solution {
    public TreeNode mirrorTree(TreeNode root) {
        if(root==null) return null;
        TreeNode temp=root.left;
        root.left=root.right;
        root.right=temp;
        mirrorTree(root.left);
        mirrorTree(root.right);
        return root;
    }
}
```



从上到下打印二叉树：

```java
class Solution{
  public int[] levelOrder(TreeNode root){
    if(root==null){
      return new int[0];
    }
    Queue<TreeNode> q=new LinkedList<>();
    List<Integer> list=new ArrayList<>();
    q.offer(root);
    
    while(!q.isEmpty()){
      TreeNode node=q.poll();
      list.add(node.val);
      if(node.left!=null){
        q.offer(node.left);
      }
      if(node.right!=null){
        q.offer(node.right);
      }
    }
    
    int[] res=new int[list.size()];
    for(int i=0;i<list.size();i++){
      res[i]=list.get(i);
    }
    return res;
  }
}
```



#### 15.怎么求最短路径，如果有赋权结点？

BFS求最短路径

广度优先搜索一层一层地进行遍历，每层遍历都是以上一层遍历的结果作为起点，遍历一个距离能访问到的所有节点。第一次遍历到目的节点，其所经过的路径为最短路径。

有权重的话Dijkstra算法



#### 16.BST树的特点

二叉查找树中左子树上所有结点的数据都小于等于根结点的数据，而右子树上所有结点的数据都大于根结点的数据



#### 17.平衡树

AVL：左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树



红黑树：平衡的二叉查找树

解决二叉查找树多次插入新节点导致的不平衡

**深度为k的二叉树，最多有2^k-1个节点**

**一棵有n个节点的红黑树高度h至多为2log(n+1)**



节点红色或黑色

根节点黑色

每个叶子的节点都是黑色的空节点

每个红色节点的两个子节点都是黑色的

从任意节点到其每个叶子的所有路径都包含相同的黑色节点



B树：平衡多路查找树

结点最大的孩子数目称为B树的阶。

一个m阶的B树具有如下属性：

1、如果根节点不是叶结点，则其至少有两棵子树。

2、每一个内部结点都有k-1个元素和k个孩子，每一个叶子结点n都有k-1个元素

其中，m/2的向上取整<=k<=m。

3、所有叶子结点都位于同一层次上。



B+树

1、有n棵子树的结点中包含有n个关键字

2、所有的叶子结点包含全部关键字的信息，及指向含这些关键字记录的指针，叶子结点本身依关键字的大小自小而大顺序连接。

3、所有非叶子结点可以看成是索引，结点中仅含有其子树中的最大(或最小)关键字。



**为什么说B+树比B树更适合数据库索引？**

1）B+树的磁盘读写代价更低

B+树的内部结点没有指向关键字具体信息的指针

2）B+树查询效率更加稳定

所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

3）B+树便于范围查询

所有叶子结点形成有序链表，只需要遍历叶子结点就可以实现整棵树的遍历。



==数组中第k大的问题==

排序法：时间复杂度O(nlogn)

```java
public static void quickSort(int[] arr,int low,int high){
  int i,j,temp,t;
  if(low>high){
    return;
  }
  i=low;
  j=high;
  //temp就是基准位
  temp = arr[low];

  while (i<j) {
    //先看右边，依次往左递减
    while (temp<=arr[j]&&i<j) {
      j--;
    }
    //再看左边，依次往右递增
    while (temp>=arr[i]&&i<j) {
      i++;
    }
    //如果满足条件则交换
    if (i<j) {
      t = arr[j];
      arr[j] = arr[i];
      arr[i] = t;
    }

  }
  //最后将基准为与i和j相等位置的数字交换
  arr[low] = arr[i];
  arr[i] = temp;
  //递归调用左半数组
  quickSort(arr, low, j-1);
  //递归调用右半数组
  quickSort(arr, j+1, high);
}
```



插入法：(冒泡k次)  时间复杂度O(n*k)

```java
public static int bubbleSort(int[] arr,int k){
  for(int i=0;i<k;i++){
    for(int j=arr.length-1;j>=i+1;j--){
      if(arr[j]>arr[j-1]){
        int temp=arr[j-1];
        arr[j-1]=arr[j];
        arr[j]=temp;
      }
    }
  }
  return arr[k-1];
}
```



小顶堆法：维护容量为K的小顶堆

1.构建堆的时间复杂度为O(K)

2.遍历剩余数组的时间复杂度O(n-K)

3.每次调整堆的时间复杂度是O(logk)

其中2和3是嵌套关系，1和2,3是并列关系，所以总的最坏时间复杂度是**O((n-k)logk + k)**。当k远小于n的情况下，也可以近似地认为是**O(nlogk)**。

```java
public static int heapSort(int[] arr, int k) {
  PriorityQueue<Integer> heap = new PriorityQueue<>();
  for (int i : arr) {
    heap.add(i);
    if (heap.size() > k) {
      heap.poll();
    }
  }
  return heap.peek();
}
```



给定一个非空的整数数组，返回其中出现频率前 **k **高的元素。

```java
public class Solution {
    public List<Integer> topKFrequent(int[] nums, int k) {
        HashMap<Integer, Integer> count = new HashMap<>();
        for (int n : nums) {
            count.put(n, count.getOrDefault(n, 0) + 1);
        }
        PriorityQueue<Integer> heap = new PriorityQueue<>((n1,n2) -> count.get(n1) - count.get(n2));
        for (int n : count.keySet()) {
            heap.add(n);
            if (heap.size() > k)
                heap.poll();
        }
        List<Integer> top_k = new LinkedList<>();
        while (!heap.isEmpty())
            top_k.add(heap.poll());
        Collections.reverse(top_k);
        return top_k;
    }
}
```



4.分治法



#### 18.TCP三次握手和四次挥手

应用层：

​	**通过应用进程间的交互来完成特定网络应用。**

运输层：

​	**负责向两台主机进程之间的通信提供通用的数据传输服务。**

网络层：

​	**网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。**

数据链路层：

​	**在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。**

物理层：

​	**实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。**



服务器可以接收多少连接？

系统用一个4元组来唯一标识一个TCP连接：{local ip,local port,remote ip,remote port}

**client最大tcp连接数：**

​	tcp端口的数据类型是unsigned short ,端口0有特殊含义，因此本地端口最大值只有65535

**server最大tcp连接数：**

​	server通常固定在某个本地端口上监听，因此server端tcp连接4元组中只有客户端ip和客户端port是可变的，最大连接数为客户端ip数×客户端port数

**实际的tcp连接数：**

​	限制的主要因素是内存和允许的文件描述符（每个tcp连接都要占用一定内存，每个socket就是一个文件描述符），另外1024以下的端口通常为保留端口。

​	通过增加内存、修改最大文件描述符，单机最大并发TCP连接数超过10万是没问题的。

**操作系统对可以打开的最大文件数的限制**

1.进程限制

ulimit -n    输出1024

2.全局限制

cat /proc/sys/fs/file-nr   输出 9344 0 592026

分别为：

1.已经分配的文件句柄数

2.已经分配但没有使用的文件句柄数

3.最大文件句柄数



**面向连接（状态的保持）：**

​	客户端和服务端都维护一个变量，这个变量维护现在数据传输的状态。通过维护这种状态，在不可靠的IP传输之上进行可靠传输。

可靠：接收方收到的数据包是发送方所发送的数据包。



**每一条TCP连接唯一地被通信两端的两个端点（套接字）所确定。**

序号:

​	本报文段所发送的数据的第一个字节的序号

确认号：

​	期望收到对方下一个报文段的第一个数据字节的序号

确认ACK:

​	仅当ACK=1时确认号字段才有效

同步SYN:

​	在连接建立时用来同步序号                                                                                                                                                                                           

​	SYN=1表示这是一个连接请求或连接接受报文



TCP实现可靠传输：

ARQ协议：

**自动重传请求是数据链路层和传输层的错误纠正协议之一。使用确认和超时这两个机制，在不可靠的基础上实现可靠的信息传输。**



**拥塞控制：全局性的过程**，防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。

**流量控制：点对点通信量的控制**



滑动窗口实现流量控制

**TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方通过 TCP 报文段中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。

拥塞控制：

为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取拥塞窗口和接收方的接受窗口中较小的一个。

四种算法：慢开始、拥塞避免、快重传、快恢复

慢开始与拥塞避免

发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...

注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。

如果出现了超时，则令 ssthresh 为出现拥塞时的发送方窗口值的一半，然后把cwnd设置为1，执行慢开始。

快重传和快恢复

慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

**快重传：**

​	发送方一连收到三个重复确认就应当立即重传对方尚未收到的报文段

**快恢复**

​	把慢开始门限ssthresh减半，把cwnd值设置为慢开始门限ssthresh减半后的数值，然后执行拥塞避免算法。 



建立一个TCP连接，需要三次握手。

- 第一次握手：客户端发送带有SYN标志的包，服务端接收到了。服务端得出结论：客户端的发送能力、服务端的接收能力正常（SYN=1，ACK=0，选择一个初始的序号 x）
- 第二次握手：服务端发送带有SYN/ACK标志的包，客户端接收到了。客户端得到的结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。但是此时服务端并不能确认客户端的接收能力是否正常。（SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y）
- 第三次握手：客户端发送带有ACK标志的数据包，服务端接收到了。服务端得到结论：客户端的接收、发送能力正常，服务器自己的发收、接收能力也正常。（确认号为 y+1，序号为 x+1）

![三次握手](C:\Users\zj\Desktop\重要图片\三次握手.jpg)

**为什么传回SYN?**

接收端传回发送端所发送的SYN是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。

**传了SYN,为啥还要传ACK?**

双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。



断开一个TCP连接，需要四次挥手

- 客户端-发送一个连接释放报文 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，此时TCP属于半关闭状态。
- 服务器-关闭与客户端的连接，发送一个FIN给客户端
- 客户端-发回 ACK 报文确认，进入TIME-WAIT状态，等待2MSL(最大报文存活时间)后释放连接。服务端收到客户端的确认后释放连接。


![四次挥手](C:\Users\zj\Desktop\重要图片\四次挥手.jpg)


**为什么要等待2MSL后释放连接？**

1.确保最后一个确认报文能够到达。如果 服务端没收到 客户端 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。

2.为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。



close_wait:

客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。

time_wait：

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。

==当端口接受的请求数量过多的时候，就会产生大量的TIME_WAIT状态的连接==



TCP可以长连接或短连接：

长连接的话，就是要求长连接在没有数据通信时，定时发送数据包（心跳），以维持连接状态。

长连接场景是频繁交互的，微信、数据库

短连接场景是普通web网站



#### 19.进程、线程、协程

进程：操作系统资源分配的最小单位

优缺点：

优点：稳定安全，有自己独立的堆和栈

缺点：

进程切换的开销比较大

进程间的通信较为复杂和耗时



- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。



**进程通信：**

1.管道

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

它具有以下限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程或者兄弟进程中使用。

2.FIFO（命名管道）

也称为命名管道，去除了管道只能在父子进程中使用的限制。

3.消息队列

4.信号量

计数器，用于为多个进程提供对共享数据对象的访问

5.共享存储

在系统内存中开辟一块内存区，分别映射到各个进程的虚拟地址空间中，任何一个进程操作了内存区都会反映到其他进程中

因为数据不需要在进程之间复制，所以这是**最快的一种 IPC**。

**需要使用信号量**用来同步对共享存储的访问。

6.套接字

与其它通信机制不同的是，它可用于不同机器间的进程通信。





进程调度算法：

**1.1 先来先服务 first-come first-serverd（FCFS）**

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**2.1 时间片轮转**

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。



**僵尸进程**：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。

**孤儿进程**：一个父进程退出，它的一个或多个子进程还在运行，子进程将成为孤儿进程，孤儿进程将被init进程所收养；

**僵尸进程将会导致资源浪费，而孤儿进程则不会。**



线程：轻量级进程，资源调度的最小单位。多个线程共享进程的堆和方法区资源，但是每个线程有自己的程序计数器、虚拟机栈和本地方法栈

优缺点：

优点：

切换的开销小，提升了系统的并发性能

缺点：

在操作共享数据时容易出错

线程状态

![img](https://camo.githubusercontent.com/bd21f0c6bf04fe410fa5397897cc47b9278ae5cb/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31392d312d32392f4a6176612545372542412542462545372541382538422545372539412538342545372538412542362545362538302538312e706e67)



协程：轻量级线程，实际上就是让一个线程轮番执行一些任务。

优缺点：

优点：

执行效率高（切换由程序自身控制）

不需要多线程的锁机制

缺点：

无法利用多核资源

进行阻塞操作会阻塞掉整个程序



并发：

​	同一时间段，多个任务都在执行

并行：

​	单位时间内，多个任务同时执行



线程死锁：

多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。



死锁四个条件：

1. 互斥条件：该资源任意一个时刻只由一个线程占用。
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

避免死锁：

1. **破坏互斥条件** ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
2. **破坏请求与保持条件** ：一次性申请所有的资源。
3. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
4. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。



最长公共连续子串

```java
dp[i][j]---表示以str1[i]和str2[j]为结尾的最长公共子串
    public static int getCommonStrLength(String str1,String str2) {
        int len1=str1.length();
        int len2=str2.length();
        int[][] dp=new int[len1+1][len2+1];
        int max=0;
        for(int i=1;i<=len1;i++){
            for(int j=1;j<=len2;j++){
                if(str1.charAt(i-1)==str2.charAt(j-1))				{
                    dp[i][j]=dp[i-1][j-1]+1;
                    max=Math.max(max,dp[i][j]);
                }else{
                    dp[i][j]=0;
                }
            }
        }
        return max;
    }
```



#### 20.创建线程的四种方式

1.继承Thread类

2.实现Runnable接口

3.实现Callable接口，有返回值，返回值通过FutureTask进行封装

```java
public class MyCallable implements Callable<Integer>{
  public Integer call(){
    return 123;
  }
}

public static void main(String[] args) {
  MyCallable mc=new MyCallable();
  FutureTask<Integer> ft=new FutureTask<>(mc);
  Thread thread =new Thread(ft);
  thread.start();
}
```

4.通过线程池创建

Executor框架：

```java
//返回一个固定线程数量的线程池
public static ExecutorService newFixedThreadPool(int nThreads)
//返回一个只有一个线程的线程池
public static ExecutorService newSingleThreadExecutor()
//返回一个可根据实际情况调整线程数量的线程池
public static ExecutorService newCachedThreadPool()
//返回一个可以指定线程数量的线程池 
public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize)
```

线程池弊端

1） FixedThreadPool 和 SingleThreadPool：

允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 

2） CachedThreadPool：

允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。

![线程池](C:\Users\zj\Desktop\重要图片\线程池.PNG)



线程池的好处：

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

ThreadPoolExecutor 重要的参数：

- **corePoolSize :** 核心线程数线程数定义了最小可以同时运行的线程数量。

- **maximumPoolSize :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。

- **workQueue:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

- **keepAliveTime**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；

- **handler**:线程池的饱和策略
  - AbortPolicy：直接抛出异常，这是默认策略；
  - CallerRunsPolicy：用调用者所在的线程来执行任务；
  - DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；
  - DiscardPolicy：直接丢弃任务；

  **shutdown只是将线程池的状态设置为SHUTWDOWN状态，正在执行的任务会继续执行下去，没有被执行的则中断。**

  **而shutdownNow则是将线程池的状态设置为STOP，正在执行的任务则被停止，没被执行任务的则返回。**

**如何合理配置线程池？**

**业务线程池使用的情况**：CPU密集型和IO密集型

- CPU密集

CPU密集型的话，**一般配置CPU处理器个数+/-1个线程**，所谓CPU密集型就是指系统大部分时间是在做程序正常的计算任务，例如数字运算、赋值、分配内存、内存拷贝、循环、查找、排序等，这些处理都需要CPU来完成。

- IO密集

IO密集型的话，是指系统大部分时间在跟I/O交互，而这个时间线程不会占用CPU来处理，即在这个时间范围内，可以由其他线程来使用CPU，因而可以多配置一些线程，如**CPU核数*2**。

**CPU核数**/(1 - 阻塞系数)   阻塞系数在0.8~0.9之间



#### 21.锁优化

这里的锁优化主要是指 JVM 对 synchronized 的优化。

自旋锁

自旋锁的思想是让一个线程在请求一个共享数据的锁时执行自旋一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。适用于共享数据的锁定状态很短的场景。

锁消除、锁粗化

锁消除是指**对于被检测出不可能存在竞争的共享数据的锁进行消除。**

锁粗化是**如果一系列的连续操作都对同一个对象反复加锁和解锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。**

轻量级锁

它使用 CAS 操作来避免重量级锁使用互斥量的开销

偏向锁

偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。



#### 22.Synchronized和ReentrantLock类

关键字synchronized

synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。

对象锁：

同步代码块

同步实例方法

类锁：

同步一个类

同步静态方法



1.重入锁

两者都是可重入锁，同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。



2.synchronized 是 JVM实现的， 而 ReentrantLock是JDK实现的

需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成。



3.等待可中断

当持有锁的线程长期不释放锁的时候，通过lock.lockInterruptibly()来实现这个机制。正在等待的线程可以选择放弃等待，改为处理其他事情。

ReentrantLock 可中断，而 synchronized 不行。



4.公平锁

公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。

synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。可以通过 ReentrantLock类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。



5.锁绑定多个条件

一个 ReentrantLock 可以同时绑定多个 Condition 对象。

线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。



除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。



ReentrantLock的基本实现可以概括为：先通过CAS尝试获取锁。如果此时已经有线程占据了锁，那就加入AQS队列并且被挂起。当锁被释放之后，排在CLH队列队首的线程会被唤醒，然后CAS再次尝试获取锁。



#### 23.HTTP报文结构

请求报文：请求行、请求头、请求空行、请求体

响应报文：响应行、响应头、响应空行、响应体

首部字段：

通用首部字段

Date、Warning(错误和警告通知)、Cache-Control(控制缓存)



请求首部字段

User-Agent:客户端信息

Host:请求资源所在服务器

Accept:客户端或者代理能够处理的媒体类型

Accept-Charset:浏览器能够显示的字符集

Accept-Encoding：浏览器能够处理的压缩编码

Accept-Language：浏览器当前设置的语言

Referer:发出请求的页面的URL

Connection:浏览器与服务器之间连接的类型

Cookie:当前页面设置的任何Cookie



响应首部字段

Location:客户端重定向至指定URI

Server:HTTP服务器的信息

Cache-Control：控制HTTP缓存



实体首部字段

Content-Encoding：编码方式

Content-Language: 自然语言

Content-Type: 实体主体的媒体类型



#### 24.wait()和sleep()的区别

**但是本质的区别是一个是线程的运行状态控制,一个是线程之间的通讯的问题**

- wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法；
- wait() 会释放锁，sleep() 不会。
- 使用区域不同，sleep是哪都能用，wait只能在同步方法或者同步代码块中。



每个对象都可以成为锁，也就是说每个对象都可以去调用wait，notify方法，而Object类是所有类的一个父类，把这些方法放在Object中，则java中的所有对象都可以去调用这些方法了。

一个线程可以拥有多个对象锁，wait，notify，notifyAll跟对象锁之间是有一个绑定关系的，比如你用对象锁aObject调用的wait()方法，那么你只能通过aObject.notify()或者aObject.notifyAll()来唤醒这个线程，这样jvm很容易就知道应该从哪个对象锁的等待池中去唤醒线程，假如用Thread.wait()，Thread.notify()，Thread.notifyAll()来调用，虚拟机根本就不知道需要操作的对象锁是哪一个。



#### 25.JMM

JMM:主内存(实例变量，线程共享)和工作内存（线程单独，包括缓存和堆栈两部分，缓存保存的是主存中变量的拷贝，堆栈中保存的是线程的局部变量）

Minor GC和Full GC触发条件

**Minor GC**：**eden区满时，触发MinorGC（即申请一个对象时，发现eden区不够用，则触发一次MinorGC）**

**注：新生代分为三个区域，eden space, from space, to space。默认比例是8:1:1**

**复制算法保证了S1中来自S0和Eden两部分的存活对象占用连续的内存空间，避免了碎片化的发生**

Survivor的存在意义，**就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。**

在MinorGC时，会把存活的对象复制到to space区域，如果to space区域不够，则利用担保机制进入老年代区域

**Full GC:**

###### 调用System.gc()

只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。

###### 老年代空间不足

老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。

###### 空间分配担保失败

使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。



可达性分析算法：

以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。

Java 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容：

- 虚拟机栈中局部变量表中引用的对象
- 本地方法栈中 JNI 中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中的常量引用的对象


垃圾收集器：

查看默认垃圾收集器：

java -XX:+PrintCommandLineFlags -version

-XX:+UseParallelGC

-XX:+PrintGCDetails



默认使用Parallel Scavenge和Parallel old

重点关注的是：

可控的吞吐量（运行用户代码时间/(运行用户代码时间+垃圾收集时间)）

自适应调节策略

动态调整参数提供合适的停顿时间或最大的吞吐量

-XX:ParallelGCThreads=数字N 表示启动多少个GC线程



Serial:

**它为单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有的用户线程。所以不适合服务器环境。**



Parrallel:

**多个垃圾收集线程并行工作，此时用户线程是暂停的，适用于科学计算/大数据处理等弱交互场景**



ParNew(并行)收集器

其实就是Serial收集器新生代的并行多线程版本

配合老年代的CMS GC工作



CMS（Concurrent Mark Sweep）标记-清除

是一种以获取最短回收停顿时间为目标的收集器

**用户线程和垃圾收集线程同时执行(不一定是并行，可能交替执行)，不需要停顿用户线程。适用对响应时间有要求的场景**

分为以下四个流程：

- 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。
- 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。
- 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。
- 并发清除：不需要停顿。

优点：并发收集低停顿

缺点：

并发执行，对CPU资源压力大

标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。



G1（Garbage-First）

**-XX:G1HeapRegionSize**:

​	设置Region的大小

**将堆内存分割成不同的区域然后并发的对其进行垃圾回收。**

在 G1 中，新增了一个 H 区的概念，如果一个对象的大小超过了一个 Region 的 50%，那么该对象就会被直接存放进 H 区。如果一个 Region 无法存放下对象，那么就会采用连续的多个 Region 来存放该超大对象。



**1、初始标记**

仅仅是标记GC Roots能直接关联的对象，速度很快。stop the world。

**2、并发标记**

从GC Roots出发，对堆中对象进行可达性分析，找出存活对象，该阶段耗时较长，但是可与用户线程并发执行。

**3、最终标记**

主要修正在并发标记阶段因为用户线程继续运行而导致标记记录产生变动的那一部分对象的标记记录。stop the world。

**4、筛选回收**

将各个region分区的回收价值和成本进行排序，根据用户所期望的停顿时间制定回收计划。这阶段停顿用户线程。stop the world。



堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。

**G1 把堆划分成多个大小相等的独立区域（Region）**，新生代和老年代不再物理隔离。

整体来看是基于“标记 - 整理”算法实现的收集器

让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。

优点：

不会产生很多内存碎片

在停顿时间上添加了预测机制，用户可以指定期望停顿时间。

XX:MaxGCPauseMillis

缺点：

对系统造成的负载较高



java -server  JVM参数    -jar  包名



#### 26.线程同步和通信

线程同步：是多个线程同时访问同一资源，等待资源访问结束

临界区：

多线程访问独占性共享资源，不可以跨进程

互斥量：

采用互斥对象机制。只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。可以跨进程

信号量：

它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目 ，可以跨进程

事件：

通过通知操作的方式来保持线程的同步



多线程间的通信一般采取**等待/通知机制**进行实现。



java多线程同步和通信的方法有如下几种：
    1、synchronized关键字修饰方法或代码段，实现数据的互斥访问
    2、volatile修饰变量，实现多线程环境下数据的同步
    3、ReentrantLock可重入锁，实现数据的互斥访问
    4、synchronized结合Object的wait和notify方法，实现线程间的等待通知机制
    5、ReentrantLock结合Condition接口的await()和signal()方法，实现线程间的等待通知机制 


#### 27.线程安全

1.不可变对象

String、final修饰、枚举

2.互斥同步

synchronized 和 ReentrantLock。

3.非阻塞同步

CAS

CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。

JAVA中的CAS操作都是通过sun包下Unsafe类实现，而Unsafe类中的方法都是native方法，由JVM本地实现

缺点：ABA问题

**使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。**

原子引用来解决 AtomicReference

版本号机制 AtomicStampedReference(方法getStamp())



AtomicInteger

J.U.C 包里面的整数原子类 AtomicInteger 的方法调用了 Unsafe 类的 CAS 操作。

getAndIncrement()

调用的unsafe.getAndAddInt(this,valueoffset,1)方法

变量valueOffset:表示变量在内存中的偏移地址

CAS不用加锁，通过CAS比较，既保证了一致性，又保证了并发性

```java
public final int getAndAddInt(Object var1,long var2,int var4){
  int var5;
  do{
    //通过var1 var2找出的主内存中的真实的值
    var5 = this.getIntVolatile(var1,var2);
    //用当前对象的值与var5比较
 }while(!this.compareAndSwapInt(var1,var2,var5,var5+var4));
  return var5;
}
```



4.无同步方案

栈封闭

多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。

线程本地存储

可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。

**ThreadLocal类主要解决的就是让每个线程绑定自己的值**，**如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本**

**每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为key ，Object 对象为 value的键值对。**

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用,而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。

应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。



#### 28.可见性

一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。

volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性

volatile变量**不会被缓存在寄存器或者对其他处理器不可见**的地方，保证了每次读写变量都从主内存中读，跳过CPU cache这一步。当一个线程修改了这个变量的值，新值对于其他线程是立即得知的。

原语:lock cmpxchg指令（compare and exchange）



#### 29.悲观锁和乐观锁

悲观锁

共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程

`synchronized`和`ReentrantLock`

乐观锁

总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。

**CAS算法**涉及到三个操作数

- 需要读写的内存值 V（内存值）
- 进行比较的值 A（预期值）
- 拟写入的新值 B（新值）

当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个**自旋操作**，即**不断的重试**。



#### 30.spring的初始化过程

![img](https://img-blog.csdn.net/20181016110527336?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NjMyNTYx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

１、ResourceLoader从存储介质中加载Spring配置信息，并使用Resource表示这个配置文件的资源；

２、BeanDefinitionReader读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中每一个解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中；

３、容器扫描BeanDefinitionRegistry中的BeanDefinition，使用Java的反射机制自动识别出Bean工厂后处理后器（实现BeanFactoryPostProcessor接口）的Bean，然后调用这些Bean工厂后处理器对BeanDefinitionRegistry中的BeanDefinition进行加工处理。主要完成以下两项工作：

1）对使用到占位符的元素标签进行解析，得到最终的配置值，这意味对一些半成品式的BeanDefinition对象进行加工处理并得到成品的BeanDefinition对象；

2）对BeanDefinitionRegistry中的BeanDefinition进行扫描，通过Java反射机制找出所有属性编辑器的Bean（实现java.beans.PropertyEditor接口的Bean），并自动将它们注册到Spring容器的属性编辑器注册表中（PropertyEditorRegistry）；

4．Spring容器从BeanDefinitionRegistry中取出加工后的BeanDefinition，并调用InstantiationStrategy着手进行Bean实例化的工作；

5．在实例化Bean时，Spring容器使用BeanWrapper对Bean进行封装，BeanWrapper提供了很多以Java反射机制操作Bean的方法，它将结合该Bean的BeanDefinition以及容器中属性编辑器，完成Bean属性的设置工作；

6．利用容器中注册的Bean后处理器（实现BeanPostProcessor接口的Bean）对已经完成属性设置工作的Bean进行后续加工，直接装配出一个准备就绪的Bean。



#### 31.redis实现分布式锁

互斥性：任意时刻只能有一个客户端拥有锁，不能被多个客户端获取

安全性：锁只能被持有该锁的客户端删除，不能被其它客户端删除

死锁：获取锁的客户端因为某些原因而宕机，而未能释放锁，其它客户端也就无法获取该锁，需要有机制来避免该类问题的发生

高可用：当部分节点宕机，客户端仍能获取锁或者释放锁



利用set命令

```properties
set key value [EX seconds] [PX milliseconds] [NX|XX]

EX 、PX:键的过期时间
NX:只有键不存在时，才对键进行设置操作
XX:只有键已经存在时，才对键进行设置操作

互斥性（加锁）、死锁（自动续期）得到了解决

安全性
1.让获得锁的线程开启一个守护线程，用来给自己的锁续期
2.（防止误删锁）把set的value值设置成一个唯一标识（判断加锁和释放锁是两个独立操作，需要使用lua脚本）

高可用
Redlock算法
使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。

尝试从 N 个互相独立 Redis 实例获取锁；
计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，那么就认为锁获取成功了；
如果锁获取失败，就到每个实例上释放锁。
```



#### 32.消息队列

1）、通过异步处理提高系统性能（削峰、减少响应所需时间）

**在不使用消息队列服务器的时候，用户的请求数据直接写入数据库，在高并发的情况下数据库压力剧增，使得响应速度变慢。但是在使用消息队列之后，用户的请求数据发送给消息队列之后立即 返回，再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。由于消息队列服务器处理速度快于数据库（消息队列也比数据库有更好的伸缩性），因此响应速度得到大幅改善。**

**消息队列具有很好的削峰作用的功能**——即通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务

2）、降低系统耦合性

　**消息队列使利用发布-订阅模式工作，消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。** **消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合**。



RabbitMq

生产者将消息发送给交换器时，需要一个RoutingKey,当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中。

交换器类型：

fanout:广播消息

direct:把消息路由到那些BindingKey与RoutingKey完全匹配的队列中

topic:模糊匹配原则，“*”匹配一个单词，“#”匹配多个单词



#### 33.设计高可用系统

代码质量

使用集群，减少单点故障

限流

超时重传

熔断

异步调用

使用缓存



K个一组翻转链表

```java
class Solution{
  public ListNode reverseKGroup(ListNode head,int k){
    if(head==null||head.next==null){
      return head;
    } 
    ListNode tail=head;
    for(int i=0;i<k;i++){
      if(tail==null){
        return head;
      }
      tail=tail.next;
    }
    ListNode newHead=reverse(head,tail);
    head.next=reverseKGroup(tail,k);
    
    return newHead;
  }
  
  private ListNode reverse(ListNode head,ListNode tail){
    ListNode pre=null;
    ListNode next=null;
    while(head!=tail){
      next=head.next;
      head.next=pre;
      pre=head;
      head=next;
    }
    return pre;
  }
}
```



两个单向链表进行加和

例如1->2->3->4，另一个是3->4，返回一个链表1->2->6->8；不可以遍历转出数字直接加。。。

```java
先链表翻转，再求和
  private ListNode reverse(ListNode head,ListNode tail){
    ListNode pre=null;
    ListNode next=null;
    while(head!=tail){
      next=head.next;
      head.next=pre;
      pre=head;
      head=next;
    }
    return pre;
  }
      public ListNode addTwoNumbers(ListNode l1, ListNode l2) {

        ListNode p1 = l1, p2 = l2, result = new ListNode(0);
        ListNode p = result;
        int carr = 0;

        while(p1 != null || p2 != null || carr > 0)
        {
            int sum = carr;
            sum += p1 == null ? 0 : p1.val;
            sum += p2 == null ? 0 : p2.val;

            p.next = new ListNode(sum % 10);
            p = p.next;

            carr = sum / 10;

            if(p1 != null)
                p1 = p1.next;
            if(p2 != null)
                p2 = p2.next;
        }

        return result.next;

    }
```



无重复字符的最长子串

```java
class Solution {
    public int lengthOfLongestSubstring(String s) {
        if (s == null || s.length() == 0) {
            return 0;
        }
        Map<Character, Integer> map = new HashMap<>();
        int left = 0;
        int right = 0;
        int maxLength = 0;
        while (right < s.length()) {
            char ch = s.charAt(right);
            map.put(ch,map.getOrDefault(ch,0)+1);
            while(map.get(ch)>1){
                char ch1=s.charAt(left);
                map.put(ch1,map.get(ch1)-1);
                left++;
            }
            right++;
            maxLength=Math.max(maxLength,right-left);
        }
        return maxLength;
    }
}
```



矩阵的最小路径和

```java
class Solution {
    public int minPathSum(int[][] grid) {
        if (grid == null || grid[0].length == 0) {
            return 0;
        }
        int m = grid.length;
        int n = grid[0].length;
        int[][] dp = new int[m][n];
        dp[0][0]=grid[0][0];
        for(int j=1;j<n;j++){
            dp[0][j]=grid[0][j]+dp[0][j-1];
        }
        for(int i=1;i<m;i++){
            dp[i][0]=grid[i][0]+dp[i-1][0];
        }
        for(int i=1;i<m;i++){
            for(int j=1;j<n;j++){
                dp[i][j]=grid[i][j]+Math.min(dp[i][j-1],dp[i-1][j]);
            }
        }
        return dp[m-1][n-1];
    }
}
```



一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为“Start” ）。

机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。

现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？

```java
class Solution{   
       public int uniquePathsWithObstacles(int[][] obstacleGrid) {
        if (obstacleGrid == null || obstacleGrid.length == 0) {
            return 0;
        }
        int m = obstacleGrid.length;
        int n = obstacleGrid[0].length;
        if (obstacleGrid[0][0] == 1 || obstacleGrid[m - 1][n - 1] == 1) {
            return 0;
        }
        if (obstacleGrid[0][0] == 0 && m == 1 && n == 1) {
            return 1;
        }
        int[][] dp = new int[m][n];
        for (int i = 0; i < m; i++) {
            if (obstacleGrid[i][0] != 1) {
                dp[i][0] = 1;
            } else {
                break;
            }
        }
        for (int j = 0; j < n; j++) {
            if (obstacleGrid[0][j] != 1) {
                dp[0][j] = 1;
            } else {
                break;
            }
        }
        for (int i = 1; i < m; i++) {
            for (int j = 1; j < n; j++) {
                if (obstacleGrid[i][j] != 1) {
                    dp[i][j] = dp[i][j - 1] + dp[i - 1][j];
                }
            }
        }
        return dp[m - 1][n - 1];
    }
 }
```



#### 34.数据库事务

**事务是逻辑上的一组操作，要么都执行，要么都不执行。**

事务的四大特性（ACID）:

1. **原子性（Atomicity）：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. **一致性（Consistency）：** 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
3. **隔离性（Isolation）：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
4. **持久性（Durability）：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

保证原子性：

利用回滚日志(undo log)，当事务回滚时能够撤销所有已经成功执行的sql语句，他需要记录你要回滚的相应日志信息。

保持持久性：

利用redo log，数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作。当事务提交的时候，会将redo log日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据undo log和binlog内容决定回滚数据还是提交数据。

**binlog是记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志。**

保持隔离性：

锁和MVCC机制



MVCC:

**MVCC是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的删除时间。当然存储的并不是实际的时间值，而是系统版本号。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。**

SELECT
InnoDB会根据以下两个条件检查每行记录：
1、InnoDB只查找版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。
2、行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除。



Next-key Locks(解决幻读)

在可重复读的隔离级别下，使用MVCC+Next-Key Locks可以解决幻读问题。

Record Locks + Gap Locks的结合

不仅锁定一个记录上的索引，也锁定索引之间的间隙。



数据库三范式：

第一范式：任何一张表都应该有主键，并且每一个字段原子性不可再分。

第二范式：建立在第一范式的基础上，所有非主键字段完全依赖主键，不能产生部分依赖。

第三范式：建立在第二范式的基础之上，所有非主键字段直接依赖主键，不能产生传递依赖。



#### 35.数据库锁

锁的粒度来分：

行级锁和表级锁

锁的类型来分：

读写锁：

排他锁：X锁，又称写锁 for update

共享锁：S锁，又称读锁 in share mode

意向锁：

在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。



**不可重复读和幻读区别：**

不可重复读的重点是修改，比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除，比如多次读取一条记录发现记录增多或减少了。



#### 36.计网基础

网络层的作用：

选择合适的网际路由和交换结点。

子网掩码

子网掩码是一个32位的二进制数，其主作用就是将IP地址划分成网络地址和主机地址两部分，并说明该IP地址是在局域网上，还是在远程网上。

与IP地址进行一个逻辑与（AND）就可以迅速得到一个IP地址中的网络标识部分。对应于网络号部分，掩码中的值为1，而对应于主机号部分，掩码中的值为0。

子网掩码还用于将网络进一步划分为若干子网

运输层：

负责向两台主机进程之间的通信提供通用的数据传输服务。

DNS劫持：

解析成错误ip地址，使用户无法访问或发生重定向



中序遍历的递归和非递归

```java
 public class TreeNode {
     int val;
     TreeNode left;
     TreeNode right;
     TreeNode(int x) { val = x; }
 }

//递归
public void inOrderRecur(Node root) {
		if (root == null) {
			return;
		}
		inOrderRecur(root.left);
		System.out.print(root.data + " -> ");
		inOrderRecur(root.right);
}
//非递归

public void inOrder() {
        Node current = root;
        //把LinkedList作为栈使用
        LinkedList<Node> s = new LinkedList<Node>();
        while (current != null || !s.isEmpty()) {
            while (current != null) {
                s.addFirst(current);
                current = current.left;
            }
            if (!s.isEmpty()) {
                current = s.removeFirst();
                System.out.print(current.data + " -> ");
                current = current.right;
            }
        }

```



链表的入环结点

```java
//空间复杂度O(n)

public class Solution {
    public ListNode detectCycle(ListNode head) {
        Set<ListNode> visited = new HashSet<ListNode>();

        ListNode node = head;
        while (node != null) {
            if (visited.contains(node)) {
                return node;
            }
            visited.add(node);
            node = node.next;
        }

        return null;
    }
}


//空间复杂度O(1)
public class Solution {
    public ListNode detectCycle(ListNode head) {
        ListNode slow = head;
        ListNode fast = head;
        while(fast != null && fast.next != null){
            slow = slow.next;
            fast = fast.next.next;
            if(slow == fast)
                break;
        }
        if(fast == null || fast.next == null)
            return null;
        ListNode ptr = head ;
        while(slow != null && ptr != slow){
            ptr = ptr.next;
            slow = slow.next;
        }       
        return slow;
    }
}
```



#### 37.泛型

为了解决强制转换时出现的ClassCastException（类型转换异常）。

泛型：

参数化类型，所谓参数化类型，是指所操作的数据类型在定义时被指定为一个参数，然后在使用时传入具体的类型。

原理：

Java的泛型是伪泛型，Java中的泛型基本上都是在编译器这个层次来实现的。在生成的Java字节码中是不包含泛型中的类型信息的。使用泛型的时候加上的类型参数，会在编译器在编译的时候去掉。这个过程就称为类型擦除。



#### 38.反射

==反射机制==：

反射就是把java类中的各种成分映射成一个个的Java对象

JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 java 语言的反射机制。

获取Class对象的方式：

​	1.Class.forName("全类名")：将字节码文件加载进内存，返回Class对象

​		多用于配置文件，将类名定义在配置文件中，读取文件，加载类

​	2.类名.class:通过类名的属性class获取

​		多用于参数的传递

​	3.对象.getClass():getClass()方法在Object类中定义着。

​		多用于对象的获取字节码的方式

==结论：==

​	==同一个字节码文件（*.class）在一次程序运行过程中，只会被加载一次，不论通过哪一种方式获取的Class对象都是同一个==

![捕获](C:\Users\zj\Desktop\重要图片\捕获.PNG)



输出链表倒数第K个结点

```java
public class Solution {
    public ListNode FindKthToTail(ListNode head,int k) {
        ListNode p,q;
        p=q=head;
        int i=0;
        for(;p!=null;i++){
            if(i>=k){
                q=q.next;
            }
            p=p.next;
        }
        return i<k?null:q;
    }
}
```



在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。

```java
public class Solution{
  public boolean Find(int[][] array,int target){
    if(array==null||array[0].length==0) return false;
    int m = array.length;
    int n = array[0].length;
    int i = m-1;
    int j = 0;
    while(i>=0&&j<n){
      int value = array[i][j];
      if(value<target) j++;
      else if(value>target) i--;
      else{
      	return true;
        break;
      }
    }
    return false;
  }
}
```



连续子数组的最大和

```java
class Solution{
  public int maxSubArray(int[] nums){
    int len=nums.length;
    if(nums==null||len==0) return 0;
    int[] dp=new int[len];
    dp[0]=nums[0];
    int result=nums[0];
    for(int i=1;i<len;i++){
      dp[i]=Math.max(nums[i],dp[i-1]+nums[i]);
      result=Math.max(result,dp[i]);
    }
    return result;
  }
}
```



LRU缓存

```java
LinkedList储存key值，实现最近最少使用。
get：
如果存在该key，则先把LinkedList中原来的key值删除，再把key添加到LinkedList末尾，越最近使用的key越靠近LinkedList末尾。
put：

如果存在该key，也要像get一样，先把LinkedList中原来的key值删除，再把key添加到LinkedList末尾，直接调用HashMap的put方法，新的value值就会覆盖旧的value值。
如果put之前元素个数已经达到了容量，则把LinkedList中第一个元素删除，越是最近最少使用的key越靠近LinkedList头部。然后调用HashMap的put方法。
不存在该key，也没有到达容量，直接调用HashMap的put方法。

class LRUCache {
    private int capacity;
    private HashMap<Integer,Integer> map;
    private LinkedList<Integer> list;
    public LRUCache(int capacity) {
        this.capacity=capacity;
        map=new HashMap<>();
        list=new LinkedList<>();
    }
    
    public int get(int key) {
        if(map.containsKey(key)){
            list.remove((Integer)key);
            list.addLast(key);
            return map.get(key);
        }
        return -1;
    }
    
    public void put(int key, int value) {
        if(map.containsKey(key)){
            list.remove((Integer)key);
            list.addLast(key);
            map.put(key,value);
            return;
        }
        if(list.size()==capacity){
            map.remove(list.removeFirst());
            map.put(key,value);
            list.addLast(key);
        }
        else{
            map.put(key,value);
            list.addLast(key);
        }
    }
}

//LinkedHashMap
class LRUCache {

        private LinkedHashMap<Integer, Integer> hashMap;
        private int capacity;

        public LRUCache(int capacity) {
            this.capacity = capacity;
            // accessOrder: 默认为false表示按插入顺序排序， true表示按访问顺序排序
            hashMap = new LinkedHashMap<Integer, Integer>(capacity, 0.75F,true) {
                @Override
                protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
                    return size() > capacity;
                }
            };
        }

        public int get(int key) {
            return hashMap.getOrDefault(key, -1);
        }

        public void put(int key, int value) {
            hashMap.put(key, value);
        }
}
```



#### 39.String为什么是final的

主要是为了”安全性“和”效率“的缘故，因为：

1、由于String类不能被继承，所以就不会被修改，这就避免了因为继承引起的安全隐患；

2、String类在程序中出现的频率比较高，如果为了避免安全隐患，在它每次出现时都用final来修饰，这无疑会降低程序的执行效率，所以干脆直接将其设为final一提高效率；



#### 40.双亲委派模型

加载过程完成以下三件事：

- 通过类的完全限定名称获取定义该类的二进制字节流。
- 将该字节流表示的静态存储结构转换为方法区的运行时存储结构。
  - 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。

![img](https://img-blog.csdnimg.cn/20190218225012336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3JpZW1hbm5f,size_16,color_FFFFFF,t_70)





一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载。

双亲委派模型保证了Java程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类）



因为这样可以避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次。

考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时被加载，所以用户自定义类是无法加载一个自定义的ClassLoader。

因为双亲委托机制是可以打破的，你完全可以自己写一个classLoader来加载自己写的java.lang.String类，但是你会发现也不会加载成功，具体就是因为针对java.*开头的类，jvm的实现中已经保证了必须由bootstrp来加载。



- 正常情况下类加载过程会遵循双亲委派机制，依次向上级类加载器委托加载，上级都加载不了，才会自行加载。
- 如果想绕过双亲委派机制，需要覆写ClassLoader类的loadClass方法，一般不推荐这么做。
- 由于final方法defineClass的限制，正常情况下我们无法加载以“java.”开头的系统类。
- 一般自定义类加载器只需实现ClassLoader的findClass方法来加载自定义路径下的类，而不是覆写loadClass破坏双亲委派，避免带来系统安全隐患。



输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。

```java
public class Solution {
    public void reOrderArray(int [] array) {
        for(int i=0;i<array.length-1;i++){
            for(int j=0;j<array.length-1-i;j++){
                if(array[j]%2==0&&array[j+1]%2==1){
                    int t=array[j];
                    array[j]=array[j+1];
                    array[j+1]=t;
                }
            }
        }
    }
}
```



#### 41.四大引用类型

1.强引用

被强引用关联的对象不会被回收。

使用 new 一个新对象的方式来创建强引用。

2.软引用

被软引用关联的对象只有在内存不够的情况下才会被回收。

使用 SoftReference 类来创建软引用。

3.弱引用

被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。

使用 WeakReference 类来创建弱引用。

4.虚引用

为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。

使用 PhantomReference 来创建虚引用。

被垃圾回收前会放入引用队列，一种通知机制



GC管理的主要区域是Java堆，一般情况下只针对堆进行垃圾回收。方法区、栈和本地方法区不被GC所管理,因而选择这些区域内的对象作为GC roots,被GC roots引用的对象不被GC回收。

在Java语言里，可作为GC Roots对象的包括如下几种

a.虚拟机栈(栈桢中的本地变量表)中的引用的对象 
b.方法区中的类静态属性引用的对象 
c.方法区中的常量引用的对象 
d.本地方法栈中JNI的引用的对象



#### 42.HashMap和HashTable区别

底层数据结构

**JDK1.8之后**

**HashMap的底层结构是数组+链表+红黑树**

**HashTable的底层结构是数组+链表**

继承父类不同

**Hashtable继承自Dictionary类，而HashMap继承自AbstractMap类；但二者都实现了Map接口。**

扩容方法

**1.HashTable中hash数组默认大小是11，增加的方式是 arr\*2+1。**

**2.HashMap中hash数组的默认大小是16，而且一定是2的指数。**

线程安全

HashTable加了synchronize关键字，线程安全的

HashMap不是线程安全的

原因：

HashMap在put的时候，插入的元素超过了容量（由负载因子决定）的范围就会触发扩容操作，然后rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。

考虑在多线程下put操作时，执行addEntry(hash, key, value, i)，如果有产生哈希碰撞，导致两个线程得到同样的bucketIndex去存储，就可能会出现覆盖丢失的情况。

哈希碰撞：

碰撞的意思是计算得到的Hash值相同，需要放到同一个bucket中

扰动函数(减少哈希碰撞)

```java
static final int hash(Object key) {
    int h;
    // 如果key为null，则hash值为0，否则调用key的hashCode()方法
    // 并让高16位与低16位异或，这样做是为了使计算出的hash更分散
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
static int indexFor(int h, int length) {  //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的
     return h & (length-1);  //第三步 取模运算
}
```

我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，它通过h & (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。

 hash%length==hash&(length-1)的前提是 length 是2的 n 次方



重写equals()方法为什么一定要重写hashcode()方法？

在Java中的一些容器中，不允许有两个完全相同的对象，插入的时候，如果判断相同则会进行覆盖。这时候如果只重写了equals（）的方法，而不重写hashcode的方法，Object中hashcode是根据对象的存储地址转换而形成的一个哈希值。这时候就有可能因为没有重写hashcode方法，造成相同的对象散列到不同的位置而造成对象的不能覆盖的问题。



#### 43.深拷贝vs浅拷贝

1. **浅拷贝**：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝，此为浅拷贝。
2. **深拷贝**：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容，此为深拷贝。



#### 44.Cookie和Session的区别

Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式。

方式：

客户端会话技术：Cookie

实现原理：

​	服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。

​	客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。

**Cookie 一般用来保存用户信息**



服务端会话技术:  Session

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。

Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。

**Session 的主要作用就是通过服务端记录用户的状态**



#### 45.get和post区别

**作用：**

GET 用于获取资源，而 POST 用于传输实体主体。

**安全：**

安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。

GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。

**幂等性：**

幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的

GET是幂等的，POST不是幂等的

**可缓存：**

GET可缓存，POST多数情况下不可缓存

GET和POST本质上就是TCP链接，并无差别。

​	get:

​		1.请求参数会在地址栏中显示，会封装到请求行中

​		2.请求参数大小是有限制的

​		3.不太安全

​	post:

​		1.请求参数不会再地址栏中显示，会封装在请求体中（HTTP协议）

​		2.请求参数的大小没有限制

​		3.较为安全

**GET和POST还有一个重大区别，简单的说：**

==GET产生一个TCP数据包；POST产生两个TCP数据包。==

**长的说：**

==对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；==

==而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）==。



#### 46.Throwable中Exception和Error区别

![img](https://img-blog.csdn.net/20170807142419237?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaGxfamF2YQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

Error:

是程序无法处理的错误，表示运行应用程序中较严重问题。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题。例如，Java虚拟机运行错误（Virtual MachineError）

- **StackOverFlowError：** 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。（递归调用）

- **OutOfMemoryError：** 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 错误。

  包括以下种类

  ​	Java heap space（新建对象过多 字符串拼接）

  ​	GC overhead limits exceeded(并行或者并发回收器在GC回收时间过长,超过98%的时间用来做GC并且回收了不到2%的堆内存)

  ​        Direct buffer memory(NIO 中的 ByteBuffer.allocateDirect(capability))

  ​	unable to create new native thread(高并发请求服务器时出现的错误，Linux 系统默认允许单个进程可以创建的线程数是1024个)

  ​	Metaspace 在元空间生成静态类

  ​	    永久代存放的信息：

  ​		虚拟机加载的类信息(Object.class)

  ​		常量池

  ​		静态变量

  ​		即时编译后的代码

Exception:

是程序本身可以处理的异常。Exception 类有一个重要的子类 RuntimeException。RuntimeException 类及其子类表示“JVM 常用操作”引发的错误。例如，若试图使用空值对象引用、除数为零或数组越界，则分别引发运行时异常（NullPointerException、ArithmeticException）和 ArrayIndexOutOfBoundException。



#### 47.单例模式

所谓单例，就是整个程序有且仅有一个实例。该类负责创建自己的对象，同时确保只有一个对象被创建。



1.懒汉式

懒加载

线程不安全

这个实现在多线程环境下是不安全的，如果多个线程能够同时进入 `if (uniqueInstance == null)` ，并且此时 uniqueInstance 为 null，那么会有多个线程执行 `uniqueInstance = new Singleton();` 语句，这将导致实例化多次 uniqueInstance。

```java
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
  
    public static Singleton getInstance() {  
    if (instance == null) {  
        instance = new Singleton();  
    }  
    return instance;  
    }  
}
```



2.饿汉式

不是懒加载

多线程安全

线程不安全问题主要是由于 uniqueInstance 被实例化多次，采取直接实例化 uniqueInstance 的方式就不会产生线程不安全问题。

但是直接实例化的方式也丢失了延迟实例化带来的节约资源的好处。

```java
public class Singleton {  
    private static Singleton instance = new Singleton();  
    private Singleton (){}  
    public static Singleton getInstance() {  
    return instance;  
    }  
}
```



3.双重校验

uniqueInstance 只需要被实例化一次，之后就可以直接使用了。加锁操作只需要对实例化那部分的代码进行，只有当 uniqueInstance 没有被实例化时，才需要进行加锁。

**第一个 if 语句用来避免 uniqueInstance 已经被实例化之后的加锁操作，而第二个 if 语句进行了加锁，所以只能有一个线程进入，就不会出现 uniqueInstance == null 时两个线程同时进行实例化操作。**

uniqueInstance 采用 **volatile 关键字修饰**也是很有必要的， `uniqueInstance = new Singleton();` 这段代码其实是分为三步执行：

1. 为 uniqueInstance 分配内存空间

2. 初始化 uniqueInstance

3. 将 uniqueInstance 指向分配的内存地址

   **指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。**

```java
public class Singleton {  
    private volatile static Singleton singleton;  
    private Singleton (){}  
    public static Singleton getSingleton() {  
      if (singleton == null) {  
          synchronized (Singleton.class) {  
            if (singleton == null) {  
                singleton = new Singleton();  
            }  
          }  
      }  
    return singleton;  
    }  
}
```



4.登记式/静态内部类

实现懒加载

当 Singleton 类被加载时，静态内部类 SingletonHolder 没有被加载进内存。只有当调用 `getUniqueInstance()` 方法从而触发 `SingletonHolder.INSTANCE` 时 SingletonHolder 才会被加载，此时初始化 INSTANCE 实例，并且 JVM 能确保 INSTANCE 只被实例化一次。

**这种方式不仅具有延迟初始化的好处，而且由 JVM 提供了对线程安全的支持。**

```java
public class Singleton {  
    private static class SingletonHolder {  
   		private static final Singleton INSTANCE = new Singleton();  
    }  
    private Singleton (){}  
    public static final Singleton getInstance() {  
    	return SingletonHolder.INSTANCE;  
    }  
}
```



5.枚举

该实现可以防止反射攻击。在其它实现中，通过 setAccessible() 方法可以将私有构造函数的访问级别设置为 public，然后调用构造函数从而实例化对象，如果要防止这种攻击，需要在构造函数中添加防止多次实例化的代码。该实现是由 JVM 保证只会实例化一次，因此不会出现上述的反射攻击。

该实现在多次序列化和反序列化之后，不会得到多个实例。而其它实现需要使用 transient 修饰所有字段，并且实现序列化和反序列化的方法。

```java
public enum Singleton {
    INSTANCE;
    public void doSomething() {
        System.out.println("doSomething");
    }
}

public class Main {
    public static void main(String[] args) {
        Singleton.INSTANCE.doSomething();
    }
}
```





#### 48.设计模式

**简单工厂模式**指由一个工厂对象来创建实例

**简单工厂把实例化的操作单独放到一个类中，这个类就成为简单工厂类，让简单工厂类来决定应该用哪个具体子类来实例化。**

```java
public class SimpleFactory {

    public Product createProduct(int type) {
        if (type == 1) {
            return new ConcreteProduct1();
        } else if (type == 2) {
            return new ConcreteProduct2();
        }
        return new ConcreteProduct();
    }
}
```

Spring 中的 BeanFactory 使用简单工厂模式，根据传入一个唯一的标识来获得 Bean 对象。




**工厂方法模式**指定义一个创建对象的接口，让接口的实现类决定创建哪种对象，让类的实例化推迟到子类中进行。

Spring 的 FactoryBean 接口的 getObject 方法也是工厂方法。

```java
public interface Factory{
  Product factoryMethod();
}

public class ConcreteFactory implements Factory{
  public Product factoryMethod(){
    return new ConcreteProduct();
  }
}
```



**抽象工厂模式**指提供一个创建一系列相关或相互依赖对象的接口，无需指定它们的具体类。

```java
public abstract class AbstractFactory {
    abstract AbstractProductA createProductA();
    abstract AbstractProductB createProductB();
}

public class ConcreteFactory1 extends AbstractFactory {
    AbstractProductA createProductA() {
        return new ProductA1();
    }

    AbstractProductB createProductB() {
        return new ProductB1();
    }
}
```



java.sql.Connection 接口就是一个抽象工厂，其中包括很多抽象产品如 Statement、Blob、Savepoint

等。



**代理模式**属于结构型模式，为其他对象提供一种代理以控制对这个对象的访问。优点是可以增强目标对象的功能，降低代码耦合度，扩展性好。

Spring 利用动态代理实现 AOP，如果 Bean 实现了接口就使用 JDK 代理，否则使用 CGLib 代理。



**装饰器模式**属于结构型模式，在不改变原有对象的基础上将功能附加到对象，相比继承可以更加灵活地扩展原有对象的功能。

java.io 包中，InputStream 字节输入流通过装饰器 BufferedInputStream 增强为缓冲字节输入流。

![img](https://camo.githubusercontent.com/1d5821e3316e1fa7d1804ea4be9d834108e102e4/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36623833336263322d353137612d343237302d386135652d3061356636646638636439362e706e67)



**当使用代理模式的时候，我们常常在一个代理类中创建一个对象的实例。并且，当我们使用装饰器模式的时候，我们通常的做法是将原始对象作为一个参数传给装饰者的构造器。**

**使用代理模式，代理和真实对象之间的的关系通常在编译时就已经确定了，而装饰者能够在运行时递归地被构造。**  



**适配器模式**属于结构型模式，它作为两个不兼容接口之间的桥梁，结合了两个独立接口的功能，将一个类的接口转换成另外一个接口,使得原本由于接口不兼容而不能一起工作的类可以一起工作。

java.io 包中，InputStream 字节输入流通过适配器 InputStreamReader 转换为 Reader 字符输入流。



**模板模式**属于行为型模式，使子类可以在不改变算法结构的情况下重新定义算法的某些步骤，适用于抽取子类重复代码到公共父类。



**观察者模式**属于行为型模式，也叫发布订阅模式，定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。



**策略模式**属于行为型模式，定义一系列算法，封装每个算法，并使它们可以互换。

- Strategy 接口定义了一个算法族，它们都实现了 behavior() 方法。
- Context 是使用到该算法族的类，其中的 doSomething() 方法会调用 behavior()，setStrategy(Strategy) 方法可以动态地改变 strategy 对象，也就是说能动态地改变 Context 所使用的算法。

```java
public interface QuackBehavior {
    void quack();
}

public class Quack implements QuackBehavior {
    @Override
    public void quack() {
        System.out.println("quack!");
    }
}

public class Squeak implements QuackBehavior{
    @Override
    public void quack() {
        System.out.println("squeak!");
    }
}

public class Duck {

    private QuackBehavior quackBehavior;

    public void performQuack() {
        if (quackBehavior != null) {
            quackBehavior.quack();
        }
    }

    public void setQuackBehavior(QuackBehavior quackBehavior) {
        this.quackBehavior = quackBehavior;
    }
}
```





#### 49.RESTful架构(表述性状态转移)

（1）每一个URI代表一种资源；

（2）客户端和服务器之间，传递这种资源的某种表现层；

（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现"表现层状态转化"。（GET、POST、PUT、DELETE）



#### 50.生产服务器性能变慢，怎么去查看？

整机：top(精简版 uptime)

cpu: vmstat(vmstat -n 2 3)每两秒采样一次，共采样3次

​	查看所有cpu核信息   -mpstat

​	每个进程使用cpu的用量分解信息   -pidstat

内存：free(free -m)

​	查看额外 pidstat -p 进程号 -r 采样间隔秒数

硬盘：df（df -h）

磁盘IO: iostat( iostat -xdk 2 3)

网络IO: ifstat



#### 51.生产环境出现CPU占用过高，分析思路和定位

1.top - c 命令找出CPU占比最高的java进程,按一下P可以按照CPU使用率进行排序

2.ps -ef|grep 进程 ,得知怎样的一个后台程序

3.定位到具体线程，ps -mp 3928 -o THREAD,tid,time

-m 显示所有的进程

-p pid 进程使用cpu的时间

-o 该参数后是用户自定义格式

**2、3两步合并为top -Hp PID 找出这个进程下面的线程**

-H： 设置线程模式

-p: 显示指定PID的进程

-c: 命令行列显示程序名以及参数



4.**线程ID转换为16进制格式**（英文小写格式）

5.具体的代码

jstack 进程号|grep 线程号   -A60(打印出前60行)



内存溢出和内存泄漏

内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用

内存泄露 memory leak，是指程序在申请内存后，无法释放已申请的内存空间



**内存泄漏排查**

**jps查看出当前有哪些Java进程，获取该Java进程的id后再对该进程进行处理。**



**jstack 主要用来查看某个Java进程内的线程堆栈信息。**



**jmap -heap pid**

**查看进程堆内存使用情况:包括使用的GC算法、堆配置参数和各代中堆内存使用**：



**jmap -histo[:live] pid**

查看堆内存中的对象数目、大小统计直方图，如果带上live则只统计活对象



**jstat -gcutil pid**

总结垃圾回收统计



首先通过jps找到java进程ID。然后top -p [pid]发现内存占用达到了最大值（-Xmx）。开始怀疑是由于频繁Full GC导致的，于是通过jstat -gcutil [pid] 60000查看GC的情况，其中60000表示每隔1分钟输出一次。果然是Full GC次数太多，JVM大部分时间都进行Full GC，而此时JVM会暂停其他一切工作，所以程序运行得非常慢。

那到底的程序的哪一部分导致消耗了这么多的内存呢？通过jmap -histo:live [pid]查看进程中各种类型的对象创建了多少个，以及每种类型的对象占多少内存。当我看到有个对象被创建了5千多万个实例时，我就能定位到是哪儿的问题了。



**内存溢出排查**

**前期准备**

当发生堆溢出的时候，可以让程序在崩溃时产生一份堆内存快照

产生堆内存快照的方法：

给jvm加上参数XX:+heapDumpOnOutofMemoryError

-XX:HeapDumpPath 导出堆的文件路径



使用jdk自带的可视化监视工具visualVM



#### 52.github查询

seckill in:name,readme,description

seckill stars:>=5000

seckill forks:100..200 stars:80..100

awesome加强搜索

高亮显示#L13

项目类搜索t



#### 53.JVM调优和参数配置

JVM参数类型：

标配参数

X参数

XX参数

​	 Boolean类型

​		-XX:+或-

​		jps :得到进程编号 jps -l

​		jinfo: jinfo -flag 配置项(PrintGCDetails) java进程编号

​	 KV设值类型

​		-XX:属性key=属性值value

​		-XX:MetaspaceSize=128m

​		-XX:MaxTenuringThreshold=15

​		-Xms 等价于-XX:InitialHeapSize

​		-Xmx等价于-XX:MaxHeapSize

​	 jinfo举例，如何查看当前运行程序的配置



查看JVM初始默认

java -XX:+PrintFlagsInitial

查看修改更新

java -XX:+PrintFlagsFinal

打印命令行参数

java -XX:+PrintCommandLineFlags -version



常用参数

-Xms

-Xmx

-Xss:设置单个线程栈的大小，一般默认为512k~1024k

等价 -XX:ThreadStackSize

-Xmn 设置新生代大小



-XX:MetaspaceSize 设置元空间 默认20M左右

元空间的本质和永久代类似，都是对JVM规范中方法区的实现

元空间不在虚拟机中，而是使用本地内存



-XX:+PrintGCDetails 打印GC日志



-XX:SurvivorRatio 设置新生代中eden区的比例

-XX:NewRatio 年轻代与老年代在堆结构的占比

-XX:MaxTenuringThreshold 设置垃圾最大年龄



#### 54.微服务架构遇到的问题

微服务是一种架构风格，一个大型软件应用由多个服务单元组成。系统中的服务单元可以单独部署，各个服务单元之间是松耦合的。

三大要求：高可用，高并发，高性能

四大问题？

最大的问题 - 》 网络是不可靠的

1.客户端如何访问这么多的服务？

​	API网关

2.服务与服务之间如何通信

​	同步通信

​		HTTP(Apache Http Client)

​		RPC(Dubbo 只支持 Java,Apache Thrift,gRPC)

​	异步通信

​		消息队列 Kafka RabbitMQ RocketMQ

3.这么多的服务如何管理

​	服务治理

​		服务注册与发现

​			基于客户端的服务注册与发现

​				Apache Zookeeper

​			基于服务端的服务注册与发现

​				Netflix Eureka

4.服务挂了，怎么办？

​	重试机制

​	服务熔断

​	服务降级

​	服务限流



分布式协调技术：多个进程之间的同步控制，让他们有序的去访问某种临界资源，防止造成“脏数据”的后果。核心是分布式锁。

分布式锁实现：

Memcached

Redis

Zookeeper

​	利用Zookeeper的顺序临时节点，来实现分布式锁和等待队列。



#### 55.HTTP和RPC

最本质的区别是：

RPC主要工作在TCP协议之上，HTTP服务主要工作在HTTP协议之上，效率来看的话，RPC更胜一筹。

**三个角度介绍RPC服务：RPC架构，同步异步调用，流行的RPC框架**

**一个完整的RPC架构包含了四个核心的组件**

客户端

服务端

客户端存根

​	存放服务端的地址消息，再将客户端的请求参数打包成网络信息，然后通过网络远程发送给对方。

服务端存根

​	接收客户端发送过来的信息，将消息解包，并调用本地的方法。



同步调用：

​	客户端等待调用执行完成并返回结果

异步调用：

​	客户端不等待调用执行完成返回结果，不过依然可以通过回调函数等待收到返回结果的通知。



总结：

- RPC主要基于TCP/UDP协议；
- HTTP协议是应用层协议，是构建在传输层协议TCP之上的；
- 从效率来看的话RPC更胜一筹！
- RPC长连接：不必每次通信都像http一样去三次握手，减少网络开销；
- HTTP服务开发迭代更快：在接口不多，系统与系统之间交互比较少的情况下，http就显得更加方便；相反，在接口比较多，系统与系统之间交互比较多的情况下，http就没有RPC有优势。



#### 56.Zookeeper

既像数据结构中的树，也像文件系统的目录 

znode包含哪些元素

data：znode存储的数据信息

ACL:记录Znode的访问权限，即哪些人或哪些ip可以访问节点

stat:包含Znode的各种元数据，比如事务ID、版本号、时间戳、大小等等

child:当前节点的子节点引用

**事件通知机制**

watch注册在特定Znode上的触发器，当这个Znode发生改变，也就是调用了create,delete，SetData方法的时候，会触发Znode上注册的对应事件，请求watch的客户端会接收到异步通知。



问题：数据不同步

ZAB协议（Zookeeper Atomic Broadcast），有效解决了Zookeeper集群崩溃恢复，以及主从同步数据的问题

三种节点状态：

选举状态

如何选择，最大ZXID

从节点状态

主节点状态



#### 57.Redis

**String类型**

​	单值缓存

​		set key value

​	对象缓存

​		set user:1 value(json格式数据)

​		mset user:1:name zhangsan user:1:balance 1888（用户部分字段）

​	分布式锁

​		setnx

​	计数器

​		INCR article:readcount:100

​	web集群session共享

​		redis实现

​	分布式系统全局序列号

​		INCRBY orderId 1000 //redis批量生成序列号提升性能

**Hash类型**

hash类型的内部编码有两种：

（1）      ziplist（压缩列表）

当哈希类型的元素个数小于hash-max-ziplist-entries配置（默认512个），同时所有值都小于hash-maxziplist-value配置（默认为64字节），Redis会使用ziplist做为哈希的内部实现。Ziplist可以使用更加紧凑的结构来实现多个元素的连续存储，所以在节省内存方面更加优秀。

（2）      hashtable（哈希表）

当哈希类型无法满足ziplist要求时，redis会采用hashtable做为哈希的内部实现，因为此时ziplist的读写效率会下降



对象缓存

​	hmset user 1:name zhangsna 1:balance 1888

**电商购物车**

1）以用户id为key

2) 商品id 为field

3)商品数量为value

购物车操作

1）添加商品 hset cart:1001 10088 1

2)增加数量 hincrby cart:1001 10088 1

3)商品总数 hlen cart:1001

4)删除商品 hdel cart:1001 10088

5)获取购物车所有商品 hgetall cart:1001



**List类型**

常用数据结构

Stack

Queue

Blocking MQ = LPUSH + BRPOP(监听)

**微博消息和微信公众号消息**

我关注了a,b大v

1)a发微博，消息ID为10018

LPUSH msg:{我的ID} 10018

2)b发微博，消息ID为10086

LPUSH msg:{我的ID} 10086

3)查看最新消息

LRANGE msg:{我的ID} 0 4



**Set类型**

微信抽奖小程序

1）点击参与抽奖加入集合

SADD key {userID}

2)查看参与抽奖所有用户

SMEMBERS key

3)抽取count名中奖者

SRANDMEMBER key [count] 不删除

SPOP key [count]  删除



微信微博点赞，收藏，标签

1）点赞

SADD like:{消息ID} 用户ID

2) 取消点赞

SREM like:{消息ID} {用户ID}

3）检查用户是否点过赞

SISMEMBER like:{消息ID} {用户ID}

4)获取点赞的用户列表

SMEMBERS  like:{消息ID}

5）获取点赞用户数

SCARD like:{消息ID}



实现微博微信关注模型

共同关注：

SINTER

我关注的人也关注他

SISMEMBER simaSet yangguo

SISMEMBER lubanSet yangguo

我可能认识的人

SDIFF yangguoSet zhugeSet



**Zset类型**

zset底层的存储结构包括ziplist或skiplist，在同时满足以下两个条件的时候使用ziplist，其他时候使用skiplist，两个条件如下：

- 有序集合保存的元素数量小于128个
- 有序集合保存的所有元素的长度小于64字节

skiplist作为zset的存储结构，整体存储结构如下图，核心点主要是包括一个dict对象和一个skiplist对象。dict保存key/value，key为元素，value为分值；skiplist保存的有序的元素列表，每个元素包括元素和分值。



实现排行榜

1）点击新闻

ZINCRBY hostNews:20200705 1 守护香港

2）展示当日排行前十

ZREVRANGE hostNews:20200705 0 9 WITHSCORES

倒序获取有序集合0-9

3)七日搜索榜单计算

ZUNIONSTORE hostNews:20190813-20190819 7 hostNews:20190813 ... hostNews:20190819



Redis 集群没有使用一致性hash, 而是引入了哈希槽的概念。

Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽。这种结构很容易添加或者删除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。

使用哈希槽的好处就在于可以方便的添加或移除节点。

当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；

当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了；

在这一点上，我们以后新增或移除节点的时候不用先停掉所有的 redis 服务。



#### 58.mysql优化

索引：包含数据和磁盘地址指针

Myisam:先走MYI，再走MYD

.frm：表结构

.MYD:表数据

.MYI:索引



Innodb

.frm:表结构

.ibd:索引+数据

聚集索引：叶节点包含了完整的数据记录



复合索引结构

**构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树。**

按照第一个键值来排序，第二个键值是无序的。只有当一个键值相等的时候，第二个键值才是按序排列的。

索引最左前缀原理





读写分离

主从数据不一致

​	强制去查询主库

​	**半同步复制**

​		**等从库同步完才返回结果，缺点吞吐量下降**

​		解决主库数据丢失问题

　		　主库写入binlog日志后，就会强制此时立即将数据同步到从库，从库将日志写入自己本地的relay log后，会返回一个ack给主库，主库接收到至少一个从库的ack之后才会认为写操作完成。

​	 **并行复制**

　　解决主从同步延时问题

　　从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行



**借助redis 这个缓冲中间件。我们按照某种规则将新增的更新的（此种操作都会发生在主库操作上）数据按照 用户ID+业务ID+其他业务维度 做成KEY 将其存储在 redis中并设置失效时间就是1秒；从库做查询时按照上述key 去redis 中查找如果存在则读取主库，如果不存在说明数据已经同步到了从库直接查从库即可。**



一般来说，如果主从延迟较为严重

1.分库，将一个主库拆分为4个主库，主库的写并发降低，主从延迟可以忽略

2.并行复制

3.重写代码，插入先更新，再查询



**主从复制**

主库将变更写binlog日志，然后从库连接到主库后，从库有一个I/O线程，将主库的binlog日志拷贝到本地，写入一个中继日志，接着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容，即在本地再次执行一遍SQL，确保跟主库的数据相同



**explain:**

type:访问类型

ALL:遍历全表以找到匹配的行

index:只遍历索引树

range:只检索给定范围的行

const、system:当Mysql对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。

**key:**

**key列显示MySQL实际决定使用的键（索引）**





#### 59.AQS（AbstractQueuedSynchronizer）

**核心思想：**

如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

![img](https://upload-images.jianshu.io/upload_images/15069341-6b4bb777b247ddda.jpg?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

AQS 使用上图的资源变量 state来表示同步状态，通过内置的 CLH FIFO 队列来完成获取资源线程的排队工作

**CountDownLatch**

用来控制一个线程等待多个线程。

维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒

```java
public class CountdownLatchExample {

    public static void main(String[] args) throws InterruptedException {
        final int totalThread = 10;
        CountDownLatch countDownLatch = new CountDownLatch(totalThread);
        ExecutorService executorService = Executors.newCachedThreadPool();
        for (int i = 0; i < totalThread; i++) {
            executorService.execute(() -> {
                System.out.print("run..");
                countDownLatch.countDown();
            });
        }
        countDownLatch.await();
        System.out.println("end");
        executorService.shutdown();
    }
}

run..run..run..run..run..run..run..run..run..run..end
```



**CyclicBarrier**

用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。

CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。

CountDownLatch的实现是基于AQS的，而CycliBarrier是基于 ReentrantLock(ReentrantLock也属于AQS同步器)和 Condition 的.

CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。

```java
public class CyclicBarrierExample {

    public static void main(String[] args) {
        final int totalThread = 10;
        CyclicBarrier cyclicBarrier = new CyclicBarrier(totalThread);
        ExecutorService executorService = Executors.newCachedThreadPool();
        for (int i = 0; i < totalThread; i++) {
            executorService.execute(() -> {
                System.out.print("before..");
                try {
                    cyclicBarrier.await();
                } catch (InterruptedException | BrokenBarrierException e) {
                    e.printStackTrace();
                }
                System.out.print("after..");
            });
        }
        executorService.shutdown();
    }
}

before..before..before..before..before..before..before..before..before..before..after..after..after..after..after..after..after..after..after..after..
```



**Semaphore**

Semaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。

两个目的：

用于多个共享资源的互斥使用

用于并发线程数的控制



以下代码模拟了对某个服务的并发请求，每次只能有 3 个客户端同时访问，请求总数为 10。

```java
public class SemaphoreExample {

    public static void main(String[] args) {
        final int clientCount = 3;
        final int totalRequestCount = 10;
        Semaphore semaphore = new Semaphore(clientCount);
        ExecutorService executorService = Executors.newCachedThreadPool();
        for (int i = 0; i < totalRequestCount; i++) {
            executorService.execute(()->{
                try {
                    semaphore.acquire();
                    System.out.print(semaphore.availablePermits() + " ");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    semaphore.release();
                }
            });
        }
        executorService.shutdown();
    }
}
```



#### 60.阻塞队列

生产者消费模式

线程池

消息中间件



juc.BlockingQueue接口有以下阻塞队列的实现：

- **FIFO 队列** ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度）
- **优先级队列** ：PriorityBlockingQueue
- SynchronousQueue:单个元素的队列

提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。



生产者消费者解决生产与消费不平衡问题。

1.有一个或多个进程是生产者，持续不断的产生数据

2.有一个或多个进程是消费者，持续不断的消耗数据

3.两者通过一个有限大小的缓冲区交换数据



当缓冲区满了，生产者应该停下来等待

当缓存区空了，消费者应该停下来



传统生产消费者模型

```java
class ShareData{
  private int number = 0;
  private Lock lock = new ReentrantLock();
  private Condition condition = lock.newCondition();
  
  public void increment() throws Exception{
    lock.lock();
    try{
      while(number != 0){
        condition.await();
      }
      number++;
  System.out.println(Thread.currentThread().getName()+"\t"+number);
      condition.signalAll();
    }catch(Exception e){
      e.printStackTrace();
    }finally{
      lock.unlock();
    }
  }
  
    public void decrement() throws Exception{
    lock.lock();
    try{
      while(number == 0){
        condition.await();
      }
      number--;
  System.out.println(Thread.currentThread().getName()+"\t"+number);
      condition.signalAll();
    }catch(Exception e){
      e.printStackTrace();
    }finally{
      lock.unlock();
    }
  }
}
```



AA线程打印5次，BB线程打印10次，CC打印15次

来10轮

用ReentrantLock中的Condition

Condition c1 = lock.newCondition();

Condition c2 = lock.newCondition();

Condition c3 = lock.newCondition();



c1.await()  ->  c2.signal()

c2.await()  -> c3.signal()



**使用BlockingQueue实现生产者消费者问题**

```java
public class ProducerConsumer {

    private static BlockingQueue<String> queue = new ArrayBlockingQueue<>(5);

    private static class Producer extends Thread {
        @Override
        public void run() {
            try {
                queue.put("product");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.print("produce..");
        }
    }

    private static class Consumer extends Thread {

        @Override
        public void run() {
            try {
                String product = queue.take();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.print("consume..");
        }
    }
}

public static void main(String[] args) {
    for (int i = 0; i < 2; i++) {
        Producer producer = new Producer();
        producer.start();
    }
    for (int i = 0; i < 5; i++) {
        Consumer consumer = new Consumer();
        consumer.start();
    }
    for (int i = 0; i < 3; i++) {
        Producer producer = new Producer();
        producer.start();
    }
}

put和take都是采用ReentantLock来实现的
```

高级版

```java
class ShareData{
  private volatile boolean FLAG = true;//默认开启，进行生产+消费
  private AtomicInteger atomicInteger = new AtomicInteger();
  
  BlockingQueue<String> blockingQueue = null;
  public ShareData(BlockingQueue<String> blockingQueue)  {
	this.blockingQueue = blockingQueue;  
    System.out.println(blockingQueue.getClass().getName());
  }
  
  public void Producer throws Exception{
    String data = null;
    boolean retValue;
    while(FLAG){
      data = atomicInteger.incrementAndGet()+"";
      retValue = blockingQueue.offer(data,2L, TimeUnit.SECONDS);
      if(retValue){
        System.out.println(Thread.currentThread().getName()+"\t 插入队列" + data+"成功");
      }else{
        System.out.println(Thread.currentThread().getName()+"\t 插入队列" + data+"失败");
      }
      TimeUnit.SECONDS.sleep(1);
    }
    System.out.println(Thread.currentThread().getName()+"Flag=false");
  }
  
  public void myConsumer() throws Exception{
    string result = null;
    while(FLAG){
      result = blockingQueue.poll(2L,TimeUnit.SECONDS);
      if(null == result || result.equalsIgnoreCase("")){
        FLAG = false;
        System.out.println(Thread.currentThread().getName()+"消费退出");
        return;
      }
      System.out.println(Thread.currentThread().getName()+"\t 消费队列" + result+"成功");
    }
  }
  
  public void stop() throws Exception{
    this.FALG = false;
  }
}
```



#### 61.死锁demo及分析

```java
class HoldLockThread implements Runnable{
  private String lockA;
  private String lockB;
  
  public HoldLockThread(string lockA,String lockB){
    this.lockA = lockA;
    this.lockB = lockB;
  }
  
  @Override
  public void run(){
    synchronized(lockA){
      System.out.println(Thread.currentThread().getName()+"\t 自己持有:"+lockA+"\t 尝试获得:" + lockB);
      try{TimeUnit.SECONDS.sleep(2);}catch(InterruptedException e){e.printStackTrace();}
      synchronized(lockB){
        System.out.println(Thread.currentThread().getName()+"\t 自己持有:"+lockB+"\t 尝试获得:" + lockA);
      }
    }
  }
}

public static void main(String[] args){
  String lockA = "lockA";
  String lockB = "lockB";
  
  new Thread(new HoldLockThread(lockA,lockB),"ThreadAAA").start();
  new Thread(new HoldLockThread(lockB,lockA),"ThreadBBB").start();
}
jps -l //查看运行java线程
jstack 进程号
```



创建线程池

```java
ExecutorService threadPool = new ThreadPoolExecutor(
			corePoolSize:2,
  			maximumPoolSize:5,
  			keepAliveTime:1L,
  			TimeUnit.SECONDS,
  			new LinkedBlockingQueue<Runnable>(capacity:3),
  			Executors.defaultThreadFactory(),
  			new ThreadPoolExecutor.CallerRunsPolicy()
);

keepAliveTime
//这个地方就是利用阻塞队列的超时时间，返回为null来完成的。
                //超过keepAliveTime还没有获取到task，则timedOut设置为true.
                     workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                    workQueue.take();
           
```



#### 62.秒杀项目

微服务的设计思想，再用分布式的部署方式

核心思想：层层过滤

- 尽量将请求拦截在上游，降低下游的压力
- 充分利用缓存与消息队列，提高请求处理速度以及削峰的作用



SpringBoot+Maven+Mysql+Redis+RabbitMQ

thymeleaf+bootstrap+jquery

模板引擎:

**就是将模板文件和数据通过模板引擎生成一个HTML代码**

ajax：

**通过在后台与服务器进行少量数据交换，Ajax 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。**



高可用：

单一职责:

​	给秒杀开个服务，使用单独数据库



**客户端优化**

**1.秒杀页面**

秒杀活动开始前，很多用户访问页面，我们把这个页面整体进行静态化，并将页面静态化之后的页面分到CDN节点上，起到压力分散的作用。

**2.防止提前下单**

计时交互，开始秒杀按钮隐藏，但知道url，通过程序不断获取最新的北京时间，可以达到毫秒级别，这种情况如何避免？

秒杀链接加盐实现动态URL

后端暴露接口的作用是：当秒杀时间开始后，才暴露每个商品的md5，只有拿到md5值，才能形成有效的秒杀请求.



**为什么加盐？**

只要明文相同，那么MD5加密后的密文就相同，于是攻击者就可以通过撞库的方式来破解出明文。加盐就是向明文中加入随机数，然后在生成MD5，这样一来即使明文相同，每次生成的MD5码也不同，如此就加大了暴力破解的难度。





**Redis集群**

主从复制、读写分离

**Redis主从同步策略**

主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。



**Nginx**

反向代理+负载均衡



**限流**



**库存预热**

1.redis+lua,库存为0直接返回售罄

2.rabbitmq串行化处理





**MD5知识：**

信息摘要：把明文内容按某种规则生成一段哈希值，即使明文消息只改动了一点，生成的结果也会完全不同。

MD5就是信息摘要的一种实现，可以从任意长度的明文字符串生成128位的哈希值。



摘要哈希生成的步骤：

1.收集相关业务参数，在这里是金额和目标账户。当然，实际应用中的参数肯定比这多得多，这里只是做了简化。

2.按照规则，把参数名和参数值拼接成一个字符串，同时把给定的密钥也拼接起来。之所以需要密钥，是因为攻击者也可能获知拼接规则

3.利用 MD5 算法，从原文生成哈希值。MD5 生成的哈希值是 128 位的二进制数，也就是 32 位的十六进制数。

![【转载】漫画趣解 MD5 算法](http://www.tomorrow.wiki/wp-content/uploads/image/20180530/1527611217648910.png)

第三方支付平台如何验证请求的签名？同样分三步：

1.发送方和请求方约定相同的字符串拼接规则，约定相同的密钥。  

2.第三方平台接到支付请求，按规则拼接业务参数和密钥，利用 MD5 算法生成 Sign。  

3.用第三方平台自己生成的 Sign 和请求发送过来的 Sign 做对比，如果两个 Sign 值一模一样，则签名无误，如果两个 Sign 值不同，则信息做了篡改。这个过程叫做验签。



**@Mapper和@Repository的区别**

 这两种注解的区别在于：

​    1、使用@mapper后，不需要在spring配置中设置扫描地址，通过mapper.xml里面的namespace属性对应相关的mapper类，spring将动态的生成Bean后注入到ServiceImpl中。

​    2、@repository则需要在Spring中配置扫描包地址，然后生成dao层的bean，之后被注入到ServiceImpl中



**第三方库Protostuff**

RuntimeSchema<User_Info>是一个专门为User_Info准备的高效序列化第三方工具类，比自带的序列化速度快，内存更省。

存取的时候是通过序列化工具类把对象序列化成一个字节数组，再把这个数据存到redis中。

LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE)的作用就是外加一个缓冲区，加快序列化速度。

byte[] bytes = ProtostuffIOUtil.toByteArray(record, schema
                    , LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE));

取得时候也是这样，获取出字节数组，在通过序列化工具反序列化到对象中：注意：先通过序列化生成一个空对象，然后在进行字节数组反向赋值。

F

**限流算法**

常用的限流算法有两种：漏桶算法和令牌桶算法。

漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。

  对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合。令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。



**错误：Failed to configure a DataSource: ‘url’ attribute is not specified and no embedded datasource could be configured.**

**解决方案：SpringBootApplication(exclude={DataSourceAutoConfiguration.class})**



**错误：mybatis-spring-1.3.2中取消了自动注入SqlSessionFactory 和 SqlSessionTemplate，所以会报出Property ‘sqlSessionFactory’ or ‘sqlSessionTemplate’ are required错误。**

**解决方案：**

```properties
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>druid-spring-boot-starter</artifactId>
    <version>1.1.10</version>
</dependency>
```



**错误：java.lang.ClassNotFoundException: com.mysql.cj.jdbc.Driver**

**com.mysql.cj.jdbc.Driver 是 mysql-connector-java 6中的**

**com.mysql.jdbc.Driver 是 mysql-connector-java 5中的**



**docker安装Rabbitmq集群**

1.安装

**docker pull rabbitmq:3.8.3**

2.数据挂载目录

 **mkdir -p /home/soft/rabbitmq/data1**

 **mkdir -p /home/soft/rabbitmq/data2**

**chmod 777 /home/soft/rabbitmq/***

3.创建容器

**docker run -d -h rabbit1 --name myrabbit1 -p 15672:15672 -p 5672:5672 -e RABBITMQ_ERLANG_COOKIE='rabbitmq_cookie' -e RABBITMQ_DEFAULT_USER='root' -e RABBITMQ_DEFAULT_PASS='123456' -v /home/soft/rabbitmq/data1:/var/lib/rabbitmq rabbitmq:3.8.3** 

**docker run -d -h rabbit2 --name myrabbit2 -p 15673:15673 -p 5673:5673 -e RABBITMQ_ERLANG_COOKIE='rabbitmq_cookie' -e RABBITMQ_DEFAULT_USER='root' -e RABBITMQ_DEFAULT_PASS='123456' -v /home/soft/rabbitmq/data2:/var/lib/rabbitmq --link myrabbit1:rabbit1 rabbitmq:3.8.3** 

4.将rabbitmq结点加入到集群中

```properties
docker exec -it myrabbit1 bash
rabbitmqctl stop_app
rabbitmqctl reset
rabbitmqctl start_app
exit

docker exec -it myrabbit2 bash
rabbitmqctl stop_app
rabbitmqctl reset
rabbitmqctl join_cluster --ram rabbit@rabbit1
rabbitmqctl start_app
exit

移除节点
rabbitmqctl stop_app && \

rabbitmqctl reset && \

rabbitmqctl start_app
```

直接访问发现无法访问，此时应该是rabbitmq需要开启web界面访问插件才行，于是进入容器执行命令开启访问功能。

docker exec -it rabbitmq1 /bin/bash

rabbitmq-plugins enable rabbitmq_management



@Resource和@Autowired

**@Resource的作用相当于@Autowired，只不过@Autowired按byType自动注入，而@Resource默认按 byName自动注入罢了。@Resource有两个属性是比较重要的，分是name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不指定name也不指定type属性，这时将通过反射机制使用byName自动注入策略。**

@Autowired默认按类型装配（这个注解是属于spring的），默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用，如下：

@Resource（这个注解属于J2EE的），默认按照名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行安装名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。



由于数据库在每次更新的时候会对seckill加锁，因此更新其实是串行执行的，不会出现多个线程同时更新一条记录的情况，所以在这里是通过数据库来保证不会出现超卖现象。

在这里虽然解决了超卖现象，但仍然有一个问题，那就是同一个用户可能发出多个请求，也就是同一个用户秒杀到了多个相同商品。

**同一个用户秒杀多个相同商品的解决思路：**

在 order 表中创建 user_phone 与 goods_id 的联合唯一索引，并且通过 @Transactional 注解的updateInventory 方法中，先生成订单，后生成秒杀订单，如果出现了同一个用户发出的多个请求，则第二次及之后的秒杀请求会导致生成秒杀订单失败，从而引起事务的回滚，这里就能保证同一个用户只能秒杀一种商品一次。

alter table user add unique index(user_id,user_name);



假设有一张订单表（table_order）业务字段为order_no（订单号），分区字段为create_tm（创建时间）；唯一索引就是联合索引order_no+create_tm。

**使用分布式锁防止并发处理**

只在新增时，使用分布式锁，避免每次处理都去获取分布式锁，影响性能。



RabbitMQ

**保证消息队列消费的幂等性？**

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。



```java
//Confirm模式：所有被publish的后续消息都将被Confirm(即ack)或者被nack一次,用于解决RabbitMQ数据同步一致性（确保消息不会丢失）
//将channel设置为Confirm模式
channel.confirmSelect();
//发布消息
channel.basicPublish("",mqConfigBean.getQueue(),MessageProperties.PERSISTENT_TEXT_PLAIN,msg.getBytes());
//普通Confirm模式
sendAck = channel.waitForConfirms(long timeout);

//消费者限流策略，每次只给消费者推送1个消息
channel.basicQos(0,1,false);

//ack进行手动签收
channel.basicConsume(mqConfigBean.getQueue(),autoAck:false,myDefaultConsumer);

DefaultConsumer中的handleDelivery方法中执行handleInRedis
```

![rabbitmq-message-lose-solution.png](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/images/rabbitmq-message-lose-solution.png?raw=true)



**rabbitmq如何实现同步调用？**

使用两个异步调用完成的，生产者投递消息到消息队列的同时，自己也作为消费者等待reply队列的返回消息，消费者接受消息队列的消息同时，也作为消息发送者发送返回消息到消息队列。

exchange有三种类型：direct、fanout、topic

topic: *表示匹配一个任意词组，#表示匹配0个或多个词组



**rabbit死信队列处理超时未支付的订单**

“死信队列”，顾明思议，是可以延时、延迟一定的时间再处理消息的一种特殊队列，它相对于“普通的队列”而言，可以实现“进入死信队列的消息不立即处理，而是可以等待一定的时间再进行处理”的功能！

**死信队列由三大核心组件组成：死信交换机+死信路由+TTL（消息存活时间~非必需的）**，而死信队列又可以由“面向生产者的基本交换机+基本路由”绑定而成，故而生产者首先是将消息发送至“基本交换机+基本路由”所绑定而成的消息模型中，即间接性地进入到死信队列中，当过了TTL，消息将“挂掉”，从而进入下一个中转站，即：“死信交换机+死信路由” 所绑定而成的**真正队列的消息模型**中，最终真正被消费者监听消费！

![img](https://img-blog.csdnimg.cn/20190731095649885.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9zdGVhZHlqYWNrLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70)

**基于redis的key失效和定时任务调度实现订单超时未支付自动失效**

![img](https://imgconvert.csdnimg.cn/aHR0cDovL3d3dy5maWdodGphdmEuY29tL2ZpbGVzL2ZpZ2h0Q29kaW5nL2Jsb2cvMjAyMDAyMDMvNDUwMjM4NzU3OTcwMjgwODE1LnBuZw?x-oss-process=image/format,png)

![img](https://imgconvert.csdnimg.cn/aHR0cDovL3d3dy5maWdodGphdmEuY29tL2ZpbGVzL2ZpZ2h0Q29kaW5nL2Jsb2cvMjAyMDAyMDMvNDUwMjM4ODQ1ODc4NzI1OTU3LnBuZw?x-oss-process=image/format,png)



**Kafka高吞吐量原因：**

1.kafka是将消息记录持久化到本地磁盘中的，采用磁盘的**顺序读写**。

2.通过操作系统的**Page Cache**，Kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。 

3.**零拷贝**（避免了在内核空间和用户空间之间的拷贝）

linux操作系统 “零拷贝” 机制使用了**sendfile方法**， 允许操作系统将数据从Page Cache 直接发送到网络，只需要最后一步的copy操作将数据复制到 NIC 缓冲区， 这样避免重新复制数据 。



**kafka cluster**：
　　　　**Broker**：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个**不重复**的编号，如图中的broker-0、broker-1等……
　　　　**Topic**：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。
　　　　**Partition**：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！
　　　　**Replication**:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。
　　　　**Message**：每一条发送的消息主体





**传统网络传输**

- JVM向OS发出read()系统调用，触发上下文切换，从用户态切换到内核态。
- 从外部存储（如硬盘）读取文件内容，通过直接内存访问（DMA）存入内核地址空间的缓冲区。
- 将数据从内核缓冲区拷贝到用户空间缓冲区，read()系统调用返回，并从内核态切换回用户态。
- JVM向OS发出write()系统调用，触发上下文切换，从用户态切换到内核态。
- 将数据从用户缓冲区拷贝到内核中与目的地Socket关联的缓冲区。
- 数据最终经由Socket通过DMA传送到硬件（如网卡）缓冲区，write()系统调用返回，并从内核态切换回用户态。



**mmap 通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。**



#### 63.计算机底层知识

![计算机组成](C:\Users\zj\Desktop\重要图片\计算机组成.PNG)



#### 64.Spring ioc扩展点

对 Spring 的 Ioc 容器来说，主要有：BeanFactoryPostProcessor， BeanPostProcessor。他们分别是在构建 BeanFactory 和构建 Bean 对象时调用。还有就是 InitializingBean 和 DisposableBean， 他们分别是在 Bean 实例创建和销毁时被调用。用户可以实现这些接口中定义的方法，Spring 就会在适当的时候调用他们。还有一个是 FactoryBean 他是个特殊的 Bean，这个 Bean 可以被用户更多的控制。



#### 65.Session共享问题

客户端在第一次访问服务端的时候，服务端会响应一个sessionId并且将它存入到本地cookie中，在之后的访问会将cookie中的sessionId放入到请求头中去访问服务器，**如果通过这个sessionid没有找到对应的数据那么服务器会创建一个新的sessionid并且响应给客户端。**

**分布式Session存在的问题？**

假设第一次访问服务A生成一个sessionid并且存入cookie中，第二次却访问服务B客户端会在cookie中读取sessionid加入到请求头中，如果在服务B通过sessionid没有找到对应的数据那么它创建一个新的并且将sessionid返回给客户端,这样并不能共享我们的Session无法达到我们想要的目的



**解决分布式一致性session**

**一、Session复制：**

修改tomcat配置

缺点：

占用内网带宽

机器较多性能下降

Session存储在内存中，容易受到机器的总内存限制

**二、如何用Cookie实现？**

即用cookie会话机制替代session会话机制，将session数据保存到客户端浏览器的cookie中，这样同一个用户访问同一网站时，无论负载均衡到哪台web服务器，都不用再去服务器请求session数据，而直接获取客户端cookie中的session数据。如此，同一个用户的登录状态就不会丢失了。
但这样做，把session数据放到客户端的cookie中，一般都是重要数据（如用户id、昵称等），会存在安全问题，但可以将session数据加密后，再存放到cookie中，来降低安全风险。



**三、修改Nginx默认的负载均衡策略，使用IP Hash的方式**



**四、session  +  redis 实现session 共享原理：**

当客户端第一次发送请求后，nginx将请求分发给服务器1 ，然后将服务器1 产生的session 放入redis中，这样的话 客户端、服务器1 和redis中都会有一个相同的session，当客户端发送第二次请求的时候，nginx将请求分发给服务器2 （已知服务器2 中无session），因为客户端自己携带了一个session，那么服务器2 就可以拿着客户端带来的session中的session ID去redis中获取session，只要拿到这个session，就能执行之后的操作。



**单点登录**

首先，用户想要访问系统A`www.java3y.com`受限的资源(比如说购物车功能，购物车功能需要登录后才能访问)，系统A`www.java3y.com`发现用户并没有登录，于是**重定向到sso认证中心，并将自己的地址作为参数**。请求的地址如下：

- `www.sso.com?service=www.java3y.com`

sso认证中心发现用户未登录，将用户引导至登录页面，用户进行输入用户名和密码进行登录，用户与认证中心建立**全局会话（生成一份Token，写到Cookie中，保存在浏览器上）**

随后，认证中心**重定向回系统A**，并把Token携带过去给系统A，重定向的地址如下：

- `www.java3y.com?token=xxxxxxx`

接着，系统A去sso认证中心验证这个Token是否正确，如果正确，则系统A和用户建立局部会话（**创建Session**）。到此，系统A和用户已经是登录状态了。

此时，用户想要访问系统B`www.java4y.com`受限的资源(比如说订单功能，订单功能需要登录后才能访问)，系统B`www.java4y.com`发现用户并没有登录，于是**重定向到sso认证中心，并将自己的地址作为参数**。请求的地址如下：

- `www.sso.com?service=www.java4y.com`

注意，因为之前用户与认证中心`www.sso.com`已经建立了全局会话（当时已经把Cookie保存到浏览器上了），所以这次系统B**重定向**到认证中心`www.sso.com`是可以带上Cookie的。

认证中心**根据带过来的Cookie**发现已经与用户建立了全局会话了，认证中心**重定向回系统B**，并把Token携带过去给系统B，重定向的地址如下：

- `www.java4y.com?token=xxxxxxx`

接着，系统B去sso认证中心验证这个Token是否正确，如果正确，则系统B和用户建立局部会话（**创建Session**）。到此，系统B和用户已经是登录状态了。



#### 66.Cookie共享问题

**1.如果在同一个Tomcat下部署多个web项目，那么这些项目中cookie能共享吗？如果能，通过什么方式实现共享？**

默认情况下不能共享。如果想共享就要设置cookie获取范围。

 setPath（String path）：设置cookie的获取范围。默认情况下会设置虚拟目录。

​         *  **如果想共享，设置path 为  " / " 。**

**2.如果在不同的Tomcat服务器间cookie的共享问题？**

* setDomain  ( String path ) ：如果设置一级域名相同，则多个服务器间的cookie可以共享。

         * setDomain(".baidu.com") ,那么 tieba.baidu.com 和 news.baidu.com 中cookie可以共享。
       ​



#### 67. 哈希算法

哈希算法（Hash）又称摘要算法（Digest），它的作用是：对任意一组输入数据进行计算，得到一个固定长度的输出摘要。

哈希算法最重要的特点就是：

- 相同的输入一定得到相同的输出；
- 不同的输入大概率得到不同的输出。

哈希算法的目的就是为了验证原始数据是否被篡改。



MD5、SHA都是摘要算法

简介：
消息摘要算法的主要特征是加密过程**不需要密钥**，并且经过加密的数据**无法被解密**

特点：
无论输入的消息有多长，计算出来的消息摘要的**长度总是固定**的
一般地，只要输入的**消息不同**，对其进行摘要以后产生的**摘要消息也必不相同**，但**相同的输入必会产生相同的输出**

**MD5:**

**MD5以512位分组来处理输入的信息，且每一分组又被划分为16个32位子分组，经过了一系列的处理后，算法的输出由四个32位分组组成，将这四个32位分组级联后将生成一个128位散列值。**

**1.数据填充**

1).附加填充位

从原始明文消息的K位之后补100...一直到512-64=448位，填充位的规则是：**只有第一个bit是1，之后都是0**

2).附加长度

这个时候，最后一个block只剩下64bits需要填充了，其内容是**原始明文的长度**。

**2.初始化MD缓冲区**

MD Buffer是4个32bits（=4bytes）的向量

**3.四轮循环运算**

主循环有四轮（MD4只有三轮），每轮循环都很相似。第一轮进行16次操作。每次操作对a、b、c和d中的其中三个作一次非线性函数运算，然后将所得结果加上第四个变量，文本的一个子分组和一个常数。再将所得结果向左环移一个不定的数，并加上a、b、c或d中之一。最后用该结果取代a、b、c或d中之一。

假设Mj表示消息的第j个子分组（从0到15），常数ti是4294967296*abs(sin(i)）的整数部分，i取值从1到64，单位是弧度。（4294967296等于2的32次方）

FF(a,b,c,d,Mj,s,ti）表示 a = b + ((a + F(b,c,d) + Mj + ti) << s)
GG(a,b,c,d,Mj,s,ti）表示 a = b + ((a + G(b,c,d) + Mj + ti) << s)

HH(a,b,c,d,Mj,s,ti）表示 a = b + ((a + H(b,c,d) + Mj + ti) << s)

Ⅱ（a,b,c,d,Mj,s,ti）表示 a = b + ((a + I(b,c,d) + Mj + ti) << s)



**分片：**

分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。

假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。

- 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。
- 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。

根据执行分片的位置，可以分为三种分片方式：

- 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。
- 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。
- 服务器分片：Redis Cluster。



**一致性hash算法**

**常用的取模方法是对服务器的数量进行取模，但是，使用上述Hash算法进行缓存时，会出现一些缺陷，主要体现在服务器数量变动的时候，所有缓存的位置都要发生改变！**

而一致性的Hash算法是对`2的32方`取模。即，一致性Hash算法将整个Hash空间组织成一个虚拟的圆环，Hash函数的值空间为`0 ~ 2^32 - 1(一个32位无符号整型)`，



整个圆环以`顺时针方向组织`，圆环正上方的点代表0，0点右侧的第一个点代表1，以此类推。

第二步，我们将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台服务器就确定在了哈希环的一个位置上，比如我们有三台机器，使用IP地址哈希后在环空间的位置如图1-4所示：



**将数据Key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针查找，遇到的服务器就是其应该定位到的服务器。**



**问题**

一致性Hash算法在服务节点太少时，容易因为节点分布不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题。

**为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射**



#### 68.分布式唯一ID

**1.UUID**

一个128bits的数

UUID.randomUUID()

**优点：**

- 性能非常高：本地生成，没有网络消耗。

**缺点：**

- 不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。
- 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
- ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用

**2.数据库生成**

**优点：**

- 非常简单，利用现有数据库系统的功能实现，成本小，有DBA专业维护。
- ID号单调自增，可以实现一些对ID有特殊要求的业务。

**缺点：**

- 强依赖DB，当DB异常时整个系统不可用，属于致命问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号。
- ID发号性能瓶颈限制在单台MySQL的读写性能。

**3.Redis生成ID**

INCR和INCRBY

**优点：**

1）不依赖于数据库，灵活方便，且性能优于数据库。

2）数字ID天然排序，对分页或者需要排序的结果很有帮助。

**缺点：**

1）如果系统中没有Redis，还需要引入新的组件，增加系统复杂度。

2）需要编码和配置的工作量比较大。

**4.雪花算法**

snowflake一共64位：

**1位标识符**：始终是0，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0。

**41位时间戳**：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。

**10位机器标识码**：可以部署在1024个节点，如果机器分机房（IDC）部署，这10位可以由 **5位机房ID + 5位机器ID** 组成。

**12位序列**：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号



**优点**

- 简单高效，生成速度快。
- 时间戳在高位，自增序列在低位，整个ID是趋势递增的，按照时间有序递增。
- 灵活度高，可以根据业务需求，调整bit位的划分，满足不同的需求。

**缺点**

- 依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。
- 在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。



#### 69.Hystrix

**服务雪崩效应是一种因服务提供者的不可用导致服务调用者的不可用,并将不可用逐渐放大的过程.如果所示:**

Hystrix的设计原则：

- 资源隔离

**Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩.**

- 熔断器

熔断器模式定义了熔断器开关相互转换的逻辑:

**服务的健康状况 = 请求失败数 / 请求总数.** 
熔断器开关由关闭到打开的状态转换是通过当前服务健康状况和设定阈值比较决定的.
​	当熔断器开关关闭时, 请求被允许通过熔断器. 如果当前健康状况高于设定阈值, 开关继续保持关闭. 如果当前健康状况低于设定阈值, 开关则切换为打开状态.当熔断器开关打开时, 请求被禁止通过.**当熔断器开关处于打开状态, 经过一段时间后, 熔断器会自动进入半开状态, 这时熔断器只允许一个请求通过**. 当该请求调用成功时, 熔断器恢复到关闭状态. 若该请求失败, 熔断器继续保持打开状态, 接下来的请求被禁止通过.熔断器的开关能保证服务调用者在调用异常服务时, 快速返回结果, 避免大量的同步等待. 并且熔断器能在一段时间后继续侦测请求执行结果, 提供恢复服务调用的可能.

- 命令模式

Hystrix使用命令模式(继承HystrixCommand类或者是HystrixObservableCommand类)来包裹具体的服务调用逻辑(run方法), 并在命令模式中添加了服务调用失败后的降级逻辑(getFallback).
同时我们在Command的构造方法中可以定义当前服务线程池和熔断器的相关参数. 



![preview](https://segmentfault.com/img/bVziap/view)

- 构建Hystrix的Command对象, 调用执行方法.
- Hystrix检查当前服务的熔断器开关是否开启, 若开启, 则执行降级服务getFallback方法.
- 若熔断器开关关闭, 则Hystrix检查当前服务的线程池是否能接收新的请求, 若超过线程池已满, 则执行降级服务getFallback方法.
- 若线程池接受请求, 则Hystrix开始执行服务调用具体逻辑run方法.
- 若服务执行失败, 则执行降级服务getFallback方法, 并将执行结果上报Metrics更新服务健康状况.
- 若服务执行超时, 则执行降级服务getFallback方法, 并将执行结果上报Metrics更新服务健康状况.
- 若服务执行成功, 返回正常结果.
- 若服务降级方法getFallback执行成功, 则返回降级结果.
- 若服务降级方法getFallback执行失败, 则抛出异常.


#### 70.Redis缓存雪崩与缓存穿透

**缓存雪崩：**

- Redis挂掉了，请求全部走数据库。

  ​	事发前：实现Redis的**高可用**(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。

  ​	事发中：万一Redis真的挂了，我们可以设置**本地缓存(ehcache)+限流(hystrix)**，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)

  ​	事发后：redis持久化，重启后自动从磁盘上加载数据，**快速恢复缓存数据**。


- 对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。

解决方法：在缓存的时候给过期时间加上一个**随机值**，这样就会大幅度的**减少缓存在同一时间过期**。



**缓存穿透**

请求的数据在缓存大量不命中，导致请求走数据库。

由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter**提前拦截**，不合法就不让这个请求到数据库层！



布隆过滤器：

我们可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高。

**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：**

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。



也就是说布隆过滤器只能判断数据是否一定不存在，而无法判断数据是否一定存在。



#### 71.Spring MVC

![img](https://img-blog.csdnimg.cn/20190601004801132.jpg)

所有的请求会转发给 DispatcherServlet 前端处理器处理，DispatcherServlet 会请求

HandlerMapping 找出容器中被 @Controler 注解修饰的 Bean 以及被 @RequestMapping 修饰的方

法和类，生成 Handler 和 HandlerInterceptor 并以一个 HandlerExcutionChain 处理器执行链的形式

返回。

```java
HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception;
```

根据请求的request，获取HandlerExecutionChain对象。



**HandlerAdapter作用**

handler（Controller，HttpRequestHandler，Servlet等）有多种实现方式

适配器模式：

1.适配器与被适配接口是继承关系
2.适配器内组合被适配接口



之后 DispatcherServlet 使用 Handler 找到对应的 HandlerApapter，通过 HandlerAdapter 调用

Handler 的方法，将请求参数绑定到方法的形参上，执行方法处理请求并得到 ModelAndView。

最后 DispatcherServlet 根据使用 ViewResolver 试图解析器对得到的 ModelAndView 逻辑视图进行解

析得到 View 物理视图，然后对视图渲染，将数据填充到视图中并返回给客户端。



ORM

ORM 即 Object-Relational Mapping ，表示对象关系映射，映射的不只是对象的值还有对象之间的关系，通过 ORM 就可以把对象映射到关系型数据库中。操作实体类就相当于操作数据库表，可以不再重点关注 SQL 语句。



**Mybatis #{} 和 ${} 的区别？**

使用 ${} 相当于使用字符串拼接，存在 SQL 注入的风险。

使用 #{} 相当于使用占位符，可以防止 SQL 注入，不支持使用占位符的地方就只能使用 ${} ，典型

情况就是动态参数。



#### 72.SpringBoot

**Spring和SpringMVC的问题在于需要配置大量的参数**

**内嵌了如Tomcat，Jetty和Undertow这样的容器，也就是说可以直接跑起来，用不着再做部署工作了。**



①、interface ：声明了这是一个java 的接口

②、@interface ： 是用来修饰 Annotation 的，请注意，它不是 interface。这个关键字声明隐含了一个信息：它是继承了 java.lang.annotation.Annotation 接口，而不是声明了一个 interface。



@SpringBootApplication

分别是@SpringBootConfiguration,@EnableAutoConfiguration,@ComponentScan



**@ComponentScan**这个注解在Spring中很重要，它对应XML配置中的元素，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。



**@EnableAutoConfiguration**

其中，最关键的要属@Import(AutoConfigurationImportSelector.class)，借助AutoConfigurationImportSelector，@EnableAutoConfiguration**可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。**

**借助于Spring框架原有的一个工具类：SpringFactoriesLoader的支持，`@EnableAutoConfiguration`可以智能的自动配置功效才得以大功告成！**

**SpringFactoriesLoader**在@EnableAutoConfiguration场景中，它更多提供了一种配置查找的功能支持，即根据@EnableAutoConfiguration的完整类名org.springframework.boot.autoconfig.EnableAutoConfiguration作为查找的Key，获得对应的一组@Configuration类。


**从classpath中搜寻所有的META-INF/spring.factories配置文件，并将其中org.springframework.boot.autoconfigure.EnableautoConfiguration对应的配置项通过反射（Java Refletion）实例化为对应的标注了@Configuration的JavaConfig形式的IoC容器配置类，然后汇总为一个并加载到IoC容器。**



**@SpringBootConfiguration**继承自@Configuration，二者功能也一致，标注当前类是配置类，可以通过`＠Bean`注解生成IOC容器管理的bean



#### 73.分布式服务接口的幂等性

其实保证幂等性主要是三点：

- **对于每个请求必须有一个唯一的标识**，举个栗子：订单支付请求，肯定得包含订单 id，一个订单 id 最多支付一次，对吧。
- **每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中记录个状态啥的**，比如支付之前记录一条这个订单的支付流水。
- **每次接收请求需要进行判断，判断之前是否处理过。**比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。



#### 74.问面试官问题

### 面对HR:

**能不能谈谈你作为一个公司老员工对公司的感受?**

**我觉得我这次表现的不是太好，你有什么建议或者评价给我吗？**

**接下来我会有一段空档期，有什么值得注意或者建议学习的吗？**

### 面对部门领导：

**未来如果我要加入这个团队，你对我的期望是什么？**

**假如我入职了，公司有什么针对性的培养方案？**

**我想要转正，那公司可以提供什么样的支持？**

**“如果我被录用了，我的具体工作是什么？”**

**您对现在的团队感受是什么样的？**

**您这个岗位在实际工作可能会面临哪些困难？**

**团队现在面临的最大挑战是什么？**

**您对于这个岗位的长期规划是什么？**



#### 74.mysql中drop、delete、truncate区别

delete：DML（数据库操作语言）可以回滚

drop、truncate:DDL（数据库定义语言）不可以回滚

 **TRUNCATE 和DELETE只删除数据，而DROP则删除整个表（结构和数据）。**



一个 SQL 执行的很慢，我们要分两种情况讨论：

1、大多数情况下很正常，偶尔很慢，则有如下原因

(1)、数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。

(2)、执行的时候，遇到锁，如表锁、行锁。

如果要判断是否真的在等待锁，我们可以用 **show processlist**这个命令来查看当前的状态

2、这条 SQL 语句一直执行的很慢，则有如下原因。

(1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。



#### 75.操作系统

中断：

程序执行过程中，遇到急需处理的事件时，暂时中止CPU上现行程序的运行，转去执行相应的事件处理程序，待处理完成后再返回原程序被中断或调度其他程序执行的过程。



1.当中断发生时，CPU立即进入核心态

2.当中断发生后，当前运行的进程暂停运行，并由操作系统内核对中断进行处理

3.对于不同的中断信号，会进行不同的处理



中断可以使CPU从用户态切换为核心态，使操作系统获得计算机的控制权。有了中断，才能实现多道程序并发执行。

核心态和用户态是通过程序状态字（PSW）的标志位



**分类：**

内中断（异常、陷入）：

​	信号的来源：CPU内部，与当前执行的指令有关

​	**内中断分类：**

​		**自愿中断** ----指令中断：系统调用（陷入）

​		**强迫中断**：

​			硬件故障-----缺页中断

​			软件中断-----算术异常、地址异常



外中断：

​	信号的来源：CPU外部，与当前执行的指令无关

​	**外中断分类：**

​		外设请求----I/O设备

​		人工干预----用户强行终止一个进程



**系统调用：**

**如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。**

系统中的各种共享资源都有操作系统统一管理，因此在用户程序中，凡是与资源相关的操作(存储分配、I/O操作、文件管理)，都必须通过系统调用的方式向操作系统提出服务请求，由操作系统代为完成。

保证系统的稳定性和安全性。



常见的系统调用

进程控制：

​	fork(); exit(); wait();

进程通信：

​	pipe(); shmget()（创建共享内存）; mmap();

文件操作：

​	open(); read(); write();

内存管理：



**虚拟内存：**

为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。



内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，**一部分存储页面号，一部分存储偏移量。**

例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

![img](https://camo.githubusercontent.com/f559d4041508ee24fd0653e58e33692f738a9b0c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63663433383661312d353863392d346563612d613137662d6531326231653937373065622e706e67)

**虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。**

**分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。**

分页与分段的比较：

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。